{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3c2d09",
   "metadata": {},
   "source": [
    "# Quantum Learning Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca71dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "qml_path = (Path.cwd() / \"../../QML\").resolve()\n",
    "sys.path.insert(0, str(qml_path))\n",
    "\n",
    "from Qsun.Qkernels import *\n",
    "from Qsun.Qgates import *\n",
    "from Qsun.Qmeas import *\n",
    "from Qsun.Qcircuit import *\n",
    "from Qsun.Qwave import *\n",
    "from Qsun.Qencodes import *\n",
    "from Qsun.Qdata import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from test_file import *\n",
    "#from src.load_datasets import *\n",
    "from src.kernel_evaluation import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804dee3f",
   "metadata": {},
   "source": [
    "### Loading 9 ansatzes from Qencodes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb087c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING_REGISTER = {\n",
    "    \"YZ_CX\": {\n",
    "        \"fn\": YZ_CX_encode,\n",
    "        \"has_params\": True,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"HighDim\": {\n",
    "        \"fn\": HighDim_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": False,\n",
    "    },\n",
    "    \"HZY_CZ\": {\n",
    "        \"fn\": HZY_CZ_encode,\n",
    "        \"has_params\": True,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"Chebyshev\": {\n",
    "        \"fn\": Chebyshev_encode,\n",
    "        \"has_params\": True,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"ParamZFeatureMap\": {\n",
    "        \"fn\": ParamZFeatureMap_encode,\n",
    "        \"has_params\": True,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"SeparableRX\": {\n",
    "        \"fn\": SeparableRXEncoding_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": False,\n",
    "    },\n",
    "    \"HardwareEfficientRx\": {\n",
    "        \"fn\": HardwareEfficientEmbeddingRx_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"ZFeatureMap\": {\n",
    "        \"fn\": ZFeatureMap_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"ZZFeatureMap\": {\n",
    "        \"fn\": ZZFeatureMap_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "}\n",
    "\n",
    "def encode_sample(sample: np.ndarray, encoding_name: str, n_layers: int = 2, \n",
    "                  params: np.ndarray = None):\n",
    "    if encoding_name not in ENCODING_REGISTER:\n",
    "        raise ValueError(f\"Unknown encoding: {encoding_name}\")\n",
    "    config = ENCODING_REGISTER[encoding_name]\n",
    "    fn = config[\"fn\"]\n",
    "    if encoding_name == \"YZ_CX\":\n",
    "        return fn(sample, params=params, n_layers=n_layers)\n",
    "    elif encoding_name == \"HZY_CZ\":\n",
    "        return fn(sample, params=params, n_layers=n_layers)\n",
    "    elif encoding_name == \"Chebyshev\":\n",
    "        return fn(sample, params=params, n_layers=n_layers)\n",
    "    elif encoding_name == \"ParamZFeatureMap\":\n",
    "        return fn(sample, params=params, n_layers=n_layers)\n",
    "    elif encoding_name == \"HardwareEfficientRx\":\n",
    "        return fn(sample, n_layers=n_layers)\n",
    "    elif encoding_name == \"ZFeatureMap\":\n",
    "        return fn(sample, n_layers=n_layers)\n",
    "    elif encoding_name == \"ZZFeatureMap\":\n",
    "        return fn(sample, n_layers=n_layers)\n",
    "    elif encoding_name == \"HighDim\":\n",
    "        return fn(sample)\n",
    "    elif encoding_name == \"SeparableRX\":\n",
    "        return fn(sample)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown encoding: {encoding_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4169a0d2",
   "metadata": {},
   "source": [
    "### Quantum Embedding Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad72be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_matrix(X_train, X_test,\n",
    "                encoding_name, n_layers=2,\n",
    "                params=None, random_state=42):\n",
    "    n_train = X_train.shape[0]\n",
    "    n_test = X_test.shape[0]\n",
    "    encoded_train = []\n",
    "    for i in range(n_train):\n",
    "        state = encode_sample(X_train[i], encoding_name, n_layers, params)\n",
    "        encoded_train.append(state)\n",
    "    encoded_test = []\n",
    "    for i in range(n_test):\n",
    "        state = encode_sample(X_test[i], encoding_name, n_layers, params)\n",
    "        encoded_test.append(state)\n",
    "    K_train = np.zeros((n_train, n_train))\n",
    "    for i in range(n_train):\n",
    "        for j in range(i, n_train):\n",
    "            k_ij = state_product(encoded_train[i], encoded_train[j])**2\n",
    "            K_train[i, j] = k_ij\n",
    "            K_train[j, i] = k_ij\n",
    "    K_test = np.zeros((n_test, n_train))\n",
    "    for i in range(n_test):\n",
    "        for j in range(n_train):\n",
    "            K_test[i, j] = state_product(encoded_test[i], encoded_train[j])**2\n",
    "    \n",
    "    return K_train, K_test\n",
    "\n",
    "def total_kernels(X_train, X_test,\n",
    "                encoding_names=None, n_layers=2,\n",
    "                random_state=42):\n",
    "    if encoding_names is None:\n",
    "        encoding_names = list(ENCODING_REGISTER.keys())\n",
    "    results = {}\n",
    "    for name in encoding_names:\n",
    "        try:\n",
    "            K_train, K_test = kernel_matrix(\n",
    "                X_train, X_test, name, n_layers, \n",
    "                random_state=random_state)\n",
    "            results[name] = (K_train, K_test)\n",
    "        except Exception as e:\n",
    "                print(f\"  Error: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_available_encodings():\n",
    "    return list(ENCODING_REGISTER.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87160210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iris dataset: Train (80, 4), Test (20, 4)\n",
      "Available encodings: ['YZ_CX', 'HighDim', 'HZY_CZ', 'Chebyshev', 'ParamZFeatureMap', 'SeparableRX', 'HardwareEfficientRx', 'ZFeatureMap', 'ZZFeatureMap']\n",
      "Sample encoding: ZFeatureMap\n"
     ]
    }
   ],
   "source": [
    "datasets = load_datasets(data_dir=\"datasets\", max_qubit=4)\n",
    "X_train, X_test, y_train, y_test = datasets[\"Iris\"]\n",
    "\n",
    "print(f\"\\nIris dataset: Train {X_train.shape}, Test {X_test.shape}\")\n",
    "print(f\"Available encodings: {get_available_encodings()}\")\n",
    "\n",
    "print(\"Sample encoding: ZFeatureMap\")\n",
    "\n",
    "K_train, K_test = kernel_matrix(\n",
    "        X_train, X_test, \"ZFeatureMap\", n_layers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcb90d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blobs_F2C2 dataset: Train (800, 2), Test (200, 2)\n",
      "\n",
      "Blobs_F2C3 dataset: Train (800, 2), Test (200, 2)\n",
      "\n",
      "Blobs_F2C4 dataset: Train (800, 2), Test (200, 2)\n",
      "\n",
      "Blobs_F4C2 dataset: Train (800, 4), Test (200, 4)\n",
      "\n",
      "Blobs_F4C3 dataset: Train (800, 4), Test (200, 4)\n",
      "\n",
      "Blobs_F4C4 dataset: Train (800, 4), Test (200, 4)\n",
      "\n",
      "Circle dataset: Train (80, 2), Test (20, 2)\n",
      "\n",
      "Moons dataset: Train (80, 2), Test (20, 2)\n",
      "\n",
      "Iris dataset: Train (80, 4), Test (20, 4)\n",
      "\n",
      "Pima dataset: Train (613, 4), Test (154, 4)\n",
      "\n",
      "Banknote dataset: Train (1097, 4), Test (275, 4)\n",
      "\n",
      "Haberman dataset: Train (244, 3), Test (61, 3)\n"
     ]
    }
   ],
   "source": [
    "datasets = load_datasets(data_dir=\"datasets\", max_qubit=4)\n",
    "for name, (X_tr, X_te, y_tr, y_te) in datasets.items():\n",
    "    print(f\"\\n{name} dataset: Train {X_tr.shape}, Test {X_te.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7326d",
   "metadata": {},
   "source": [
    "### Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e35b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_runs(dataset_name=\"Iris\", \n",
    "            encodings=None,\n",
    "            n_layers=2,\n",
    "            n_runs=10,\n",
    "            test_size=0.2,\n",
    "            random_state=42):\n",
    "    if encodings is None:\n",
    "        encodings = get_available_encodings()\n",
    "        print(f\"Dataset: {dataset_name}\") \n",
    "\n",
    "    results_accumulator = {enc: {m: {\"train\": [], \"test\": []} \n",
    "                                  for m in [\"SVM\"]} \n",
    "                           for enc in encodings}\n",
    "    for run in tqdm(range(n_runs)):\n",
    "        seed = random_state + run\n",
    "        datasets = load_datasets(data_dir=\"datasets\", random_state=seed, test_size=test_size, max_qubit=4)\n",
    "        X_train, X_test, y_train, y_test = datasets[dataset_name]\n",
    "        kernels = total_kernels(X_train, X_test, encodings, n_layers, seed)\n",
    "        for enc_name, (K_train, K_test) in kernels.items():\n",
    "            for model_name in [\"SVM\"]:\n",
    "                result = evaluate_kernel(\n",
    "                    K_train, K_test, y_train, y_test, enc_name, model_name\n",
    "                )\n",
    "                results_accumulator[enc_name][model_name][\"train\"].append(result.train_accuracy)\n",
    "                results_accumulator[enc_name][model_name][\"test\"].append(result.test_accuracy)\n",
    "    all_results = {}\n",
    "    for enc_name in encodings:\n",
    "        enc_results = []\n",
    "        for model_name in [\"SVM\"]:\n",
    "            train_scores = results_accumulator[enc_name][model_name][\"train\"]\n",
    "            test_scores = results_accumulator[enc_name][model_name][\"test\"]\n",
    "            enc_results.append(KernelEvaluation(\n",
    "                model_name=model_name,\n",
    "                encoding_name=enc_name,\n",
    "                train_accuracy=np.mean(train_scores),\n",
    "                test_accuracy=np.mean(test_scores),\n",
    "                train_std=np.std(train_scores),\n",
    "                test_std=np.std(test_scores)\n",
    "            ))\n",
    "        all_results[enc_name] = enc_results\n",
    "    \n",
    "    return {\"results\": all_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34b3aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(all_results):\n",
    "    print(f\"{'Encoding':<22} {'Model':<6} {'Train':<18} {'Test':<18}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    best_test_acc = 0\n",
    "    best_config = None\n",
    "    \n",
    "    for encoding_name, results in all_results.items():\n",
    "        for r in results:\n",
    "            train_str = f\"{r.train_accuracy:.4f} ± {r.train_std:.4f}\"\n",
    "            test_str = f\"{r.test_accuracy:.4f} ± {r.test_std:.4f}\"\n",
    "            print(f\"{r.encoding_name:<22} {r.model_name:<6} {train_str:<18} {test_str:<18}\")\n",
    "            if r.test_accuracy > best_test_acc:\n",
    "                best_test_acc = r.test_accuracy\n",
    "                best_config = r\n",
    "    \n",
    "    print(\"-\" * 75)\n",
    "    print(f\"Best: {best_config.encoding_name} + {best_config.model_name} = {best_test_acc:.4f} ± {best_config.test_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3185d4",
   "metadata": {},
   "source": [
    "## Accuracy Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecce2002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(all_results):\n",
    "    encodings = list(all_results.keys())\n",
    "    models = [\"SVM\"]\n",
    "    \n",
    "    test_accs = {m: [] for m in models}\n",
    "    test_stds = {m: [] for m in models}\n",
    "    \n",
    "    for enc in encodings:\n",
    "        for r in all_results[enc]:\n",
    "            test_accs[r.model_name].append(r.test_accuracy)\n",
    "            test_stds[r.model_name].append(r.test_std)\n",
    "    \n",
    "    x = np.arange(len(encodings))\n",
    "    width = 0.25\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        ax.bar(x + i*width, test_accs[model], width, \n",
    "               yerr=test_stds[model], label=model, capsize=3)\n",
    "    \n",
    "    ax.set_ylabel('Test Accuracy')\n",
    "    ax.set_xticks(x + width)\n",
    "    ax.set_xticklabels(encodings, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.set_ylim([0, 1.05])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92a77303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_table(all_dataset_results, \n",
    "                        model_name=\"SVM\"):\n",
    "    encodings = list(ENCODING_REGISTER.keys())\n",
    "    \n",
    "    table_data = []\n",
    "    for dataset_name, result_dict in all_dataset_results.items():\n",
    "        row = {\"Dataset\": dataset_name}\n",
    "        results = result_dict[\"results\"]\n",
    "        \n",
    "        for enc_name in encodings:\n",
    "            if enc_name in results:\n",
    "                for r in results[enc_name]:\n",
    "                    if r.model_name == model_name:\n",
    "                        row[enc_name] = f\"{r.test_accuracy:.4f}\"\n",
    "                        break\n",
    "            else:\n",
    "                row[enc_name] = \"-\"\n",
    "        \n",
    "        table_data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(table_data)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac238f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Blobs_F2C2\n",
      "------------------------------------------------------------\n",
      "Dataset: Blobs_F2C2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:53<00:00,  5.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Blobs_F2C3\n",
      "------------------------------------------------------------\n",
      "Dataset: Blobs_F2C3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:00<00:00,  6.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Blobs_F2C4\n",
      "------------------------------------------------------------\n",
      "Dataset: Blobs_F2C4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:56<00:00,  5.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Blobs_F4C2\n",
      "------------------------------------------------------------\n",
      "Dataset: Blobs_F4C2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:20<00:00,  8.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Blobs_F4C3\n",
      "------------------------------------------------------------\n",
      "Dataset: Blobs_F4C3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:12<00:00,  7.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Blobs_F4C4\n",
      "------------------------------------------------------------\n",
      "Dataset: Blobs_F4C4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:09<00:00,  6.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Circle\n",
      "------------------------------------------------------------\n",
      "Dataset: Circle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Moons\n",
      "------------------------------------------------------------\n",
      "Dataset: Moons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Iris\n",
      "------------------------------------------------------------\n",
      "Dataset: Iris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Pima\n",
      "------------------------------------------------------------\n",
      "Dataset: Pima\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:44<00:00,  4.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Banknote\n",
      "------------------------------------------------------------\n",
      "Dataset: Banknote\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:03<00:00, 12.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Haberman\n",
      "------------------------------------------------------------\n",
      "Dataset: Haberman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "SUMMARY TABLE (Test Accuracy - SVM)\n",
      "--------------------------------------------------------------------------------\n",
      "       Dataset   YZ_CX HighDim  HZY_CZ Chebyshev ParamZFeatureMap SeparableRX HardwareEfficientRx ZFeatureMap ZZFeatureMap\n",
      "0   Blobs_F2C2  0.5045  0.9990  0.9995    0.6970           0.8315      0.9995              0.9980      0.9755       0.9800\n",
      "1   Blobs_F2C3  0.3270  0.9995  1.0000    0.5105           0.7100      1.0000              0.9995      0.9995       0.9965\n",
      "2   Blobs_F2C4  0.2265  0.9985  0.9985    0.4380           0.5990      0.9980              0.9985      0.9970       0.9930\n",
      "3   Blobs_F4C2  0.5050  1.0000  1.0000    0.6720           0.9220      1.0000              1.0000      1.0000       0.9970\n",
      "4   Blobs_F4C3  0.3395  1.0000  1.0000    0.5115           0.8340      1.0000              1.0000      1.0000       0.9975\n",
      "5   Blobs_F4C4  0.2445  1.0000  1.0000    0.4155           0.7430      1.0000              1.0000      1.0000       0.9985\n",
      "6       Circle  0.5000  0.9100  0.9450    0.5100           0.6400      0.9700              0.9700      0.9900       0.7100\n",
      "7        Moons  0.5000  0.9700  0.8600    0.5900           0.6300      0.8350              0.7950      0.9350       0.8200\n",
      "8         Iris  0.5250  1.0000  1.0000    0.6000           0.8500      1.0000              1.0000      0.9600       0.8600\n",
      "9         Pima  0.6266  0.7481  0.7519    0.6130           0.6513      0.7455              0.7474      0.7545       0.7091\n",
      "10    Banknote  0.5058  0.9938  0.9844    0.5436           0.5833      0.9985              1.0000      0.9662       0.9891\n",
      "11    Haberman  0.7311  0.7328  0.7230    0.7377           0.7475      0.7164              0.7344      0.7508       0.7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = load_datasets(data_dir=\"datasets\", max_qubit=4)\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for dataset_name in datasets.keys():\n",
    "    print(f\"Processing: {dataset_name}\")\n",
    "    print('-'*60)\n",
    "    \n",
    "    result = total_runs(\n",
    "        dataset_name=dataset_name,\n",
    "        n_layers=2,\n",
    "        n_runs=10,\n",
    "        random_state=42)\n",
    "    all_results[dataset_name] = result\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"SUMMARY TABLE (Test Accuracy - SVM)\")\n",
    "print(\"-\"*80)\n",
    "df_svm = create_summary_table(all_results, model_name=\"SVM\")\n",
    "print(df_svm.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "854a87f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_70d5b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_70d5b_level0_col0\" class=\"col_heading level0 col0\" >Dataset</th>\n",
       "      <th id=\"T_70d5b_level0_col1\" class=\"col_heading level0 col1\" >Best_Kernel</th>\n",
       "      <th id=\"T_70d5b_level0_col2\" class=\"col_heading level0 col2\" >Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_70d5b_row0_col0\" class=\"data row0 col0\" >Blobs_F2C2</td>\n",
       "      <td id=\"T_70d5b_row0_col1\" class=\"data row0 col1\" >HZY_CZ</td>\n",
       "      <td id=\"T_70d5b_row0_col2\" class=\"data row0 col2\" >0.999500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_70d5b_row1_col0\" class=\"data row1 col0\" >Blobs_F2C3</td>\n",
       "      <td id=\"T_70d5b_row1_col1\" class=\"data row1 col1\" >HZY_CZ</td>\n",
       "      <td id=\"T_70d5b_row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_70d5b_row2_col0\" class=\"data row2 col0\" >Blobs_F2C4</td>\n",
       "      <td id=\"T_70d5b_row2_col1\" class=\"data row2 col1\" >HighDim</td>\n",
       "      <td id=\"T_70d5b_row2_col2\" class=\"data row2 col2\" >0.998500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_70d5b_row3_col0\" class=\"data row3 col0\" >Blobs_F4C2</td>\n",
       "      <td id=\"T_70d5b_row3_col1\" class=\"data row3 col1\" >HighDim</td>\n",
       "      <td id=\"T_70d5b_row3_col2\" class=\"data row3 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_70d5b_row4_col0\" class=\"data row4 col0\" >Blobs_F4C3</td>\n",
       "      <td id=\"T_70d5b_row4_col1\" class=\"data row4 col1\" >HighDim</td>\n",
       "      <td id=\"T_70d5b_row4_col2\" class=\"data row4 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_70d5b_row5_col0\" class=\"data row5 col0\" >Blobs_F4C4</td>\n",
       "      <td id=\"T_70d5b_row5_col1\" class=\"data row5 col1\" >HighDim</td>\n",
       "      <td id=\"T_70d5b_row5_col2\" class=\"data row5 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_70d5b_row6_col0\" class=\"data row6 col0\" >Circle</td>\n",
       "      <td id=\"T_70d5b_row6_col1\" class=\"data row6 col1\" >ZFeatureMap</td>\n",
       "      <td id=\"T_70d5b_row6_col2\" class=\"data row6 col2\" >0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_70d5b_row7_col0\" class=\"data row7 col0\" >Moons</td>\n",
       "      <td id=\"T_70d5b_row7_col1\" class=\"data row7 col1\" >HighDim</td>\n",
       "      <td id=\"T_70d5b_row7_col2\" class=\"data row7 col2\" >0.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_70d5b_row8_col0\" class=\"data row8 col0\" >Iris</td>\n",
       "      <td id=\"T_70d5b_row8_col1\" class=\"data row8 col1\" >HighDim</td>\n",
       "      <td id=\"T_70d5b_row8_col2\" class=\"data row8 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_70d5b_row9_col0\" class=\"data row9 col0\" >Pima</td>\n",
       "      <td id=\"T_70d5b_row9_col1\" class=\"data row9 col1\" >ZFeatureMap</td>\n",
       "      <td id=\"T_70d5b_row9_col2\" class=\"data row9 col2\" >0.754545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_70d5b_row10_col0\" class=\"data row10 col0\" >Banknote</td>\n",
       "      <td id=\"T_70d5b_row10_col1\" class=\"data row10 col1\" >HardwareEfficientRx</td>\n",
       "      <td id=\"T_70d5b_row10_col2\" class=\"data row10 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_70d5b_row11_col0\" class=\"data row11 col0\" >Haberman</td>\n",
       "      <td id=\"T_70d5b_row11_col1\" class=\"data row11 col1\" >ZFeatureMap</td>\n",
       "      <td id=\"T_70d5b_row11_col2\" class=\"data row11 col2\" >0.750820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1dcbbaf0a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_dataframe(all_dataset_results, \n",
    "                          model_name=\"SVM\"):\n",
    "\n",
    "    encodings = list(ENCODING_REGISTER.keys())\n",
    "    \n",
    "    table_data = []\n",
    "    for dataset_name, result_dict in all_dataset_results.items():\n",
    "        results = result_dict[\"results\"]\n",
    "        \n",
    "        best_acc = 0\n",
    "        best_kernel = None\n",
    "        \n",
    "        for enc_name in encodings:\n",
    "            if enc_name in results:\n",
    "                for r in results[enc_name]:\n",
    "                    if r.model_name == model_name:\n",
    "                        if r.test_accuracy > best_acc:\n",
    "                            best_acc = r.test_accuracy\n",
    "                            best_kernel = enc_name\n",
    "                        break\n",
    "        \n",
    "        table_data.append({\n",
    "            \"Dataset\": dataset_name,\n",
    "            \"Best_Kernel\": best_kernel,\n",
    "            \"Test Accuracy\": best_acc\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(table_data)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_best = label_dataframe(all_results, model_name=\"SVM\")\n",
    "df_best.style.hide(axis='index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

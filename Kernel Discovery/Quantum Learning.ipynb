{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3c2d09",
   "metadata": {},
   "source": [
    "# Quantum Learning Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71dbd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'load_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mload_datasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkernel_evaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'load_datasets'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "qml_path = (Path.cwd() / \"../../QML\").resolve()\n",
    "sys.path.insert(0, str(qml_path))\n",
    "\n",
    "from Qsun.Qkernels import *\n",
    "from Qsun.Qgates import *\n",
    "from Qsun.Qmeas import *\n",
    "from Qsun.Qcircuit import *\n",
    "from Qsun.Qwave import *\n",
    "from Qsun.Qencodes import *\n",
    "from Qsun.Qdata import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.load_datasets import *\n",
    "from src.kernel_evaluation import *\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Tuple, Callable, List\n",
    "from itertools import combinations\n",
    "import problexity as px\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804dee3f",
   "metadata": {},
   "source": [
    "### Loading 9 ansatzes from Qencodes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb087c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING_REGISTER = {\n",
    "    \"YZ_CX\": {\n",
    "        \"fn\": YZ_CX_encode,\n",
    "        \"has_params\": True,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"HighDim\": {\n",
    "        \"fn\": HighDim_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": False,\n",
    "    },\n",
    "    \"HZY_CZ\": {\n",
    "        \"fn\": HZY_CZ_encode,\n",
    "        \"has_params\": True,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"Chebyshev\": {\n",
    "        \"fn\": Chebyshev_encode,\n",
    "        \"has_params\": True,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"ParamZFeatureMap\": {\n",
    "        \"fn\": ParamZFeatureMap_encode,\n",
    "        \"has_params\": True,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"SeparableRX\": {\n",
    "        \"fn\": SeparableRXEncoding_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": False,\n",
    "    },\n",
    "    \"HardwareEfficientRx\": {\n",
    "        \"fn\": HardwareEfficientEmbeddingRx_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"ZFeatureMap\": {\n",
    "        \"fn\": ZFeatureMap_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"ZZFeatureMap\": {\n",
    "        \"fn\": ZZFeatureMap_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "}\n",
    "\n",
    "def encode_sample(sample: np.ndarray, encoding_name: str, n_layers: int = 2, \n",
    "                  params: np.ndarray = None):\n",
    "    if encoding_name not in ENCODING_REGISTER:\n",
    "        raise ValueError(f\"Unknown encoding: {encoding_name}\")\n",
    "    config = ENCODING_REGISTER[encoding_name]\n",
    "    fn = config[\"fn\"]\n",
    "    if encoding_name == \"YZ_CX\":\n",
    "        return fn(sample, params=params, n_layers=n_layers)\n",
    "    elif encoding_name == \"HZY_CZ\":\n",
    "        return fn(sample, params=params, n_layers=n_layers)\n",
    "    elif encoding_name == \"Chebyshev\":\n",
    "        return fn(sample, params=params, n_layers=n_layers)\n",
    "    elif encoding_name == \"ParamZFeatureMap\":\n",
    "        return fn(sample, params=params, n_layers=n_layers)\n",
    "    elif encoding_name == \"HardwareEfficientRx\":\n",
    "        return fn(sample, n_layers=n_layers)\n",
    "    elif encoding_name == \"ZFeatureMap\":\n",
    "        return fn(sample, n_layers=n_layers)\n",
    "    elif encoding_name == \"ZZFeatureMap\":\n",
    "        return fn(sample, n_layers=n_layers)\n",
    "    elif encoding_name == \"HighDim\":\n",
    "        return fn(sample)\n",
    "    elif encoding_name == \"SeparableRX\":\n",
    "        return fn(sample)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown encoding: {encoding_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4169a0d2",
   "metadata": {},
   "source": [
    "### Quantum Embedding Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad72be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_matrix(X_train: np.ndarray, X_test: np.ndarray,\n",
    "                                    encoding_name: str, n_layers: int = 2,\n",
    "                                    params: np.ndarray = None, random_state: int = 42,\n",
    "                                    verbose: bool = True) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    n_train = X_train.shape[0]\n",
    "    n_test = X_test.shape[0]\n",
    "    encoded_train = []\n",
    "    for i in range(n_train):\n",
    "        state = encode_sample(X_train[i], encoding_name, n_layers, params)\n",
    "        encoded_train.append(state)\n",
    "    encoded_test = []\n",
    "    for i in range(n_test):\n",
    "        state = encode_sample(X_test[i], encoding_name, n_layers, params)\n",
    "        encoded_test.append(state)\n",
    "    K_train = np.zeros((n_train, n_train))\n",
    "    for i in range(n_train):\n",
    "        for j in range(i, n_train):\n",
    "            k_ij = state_product(encoded_train[i], encoded_train[j])**2\n",
    "            K_train[i, j] = k_ij\n",
    "            K_train[j, i] = k_ij\n",
    "    K_test = np.zeros((n_test, n_train))\n",
    "    for i in range(n_test):\n",
    "        for j in range(n_train):\n",
    "            K_test[i, j] = state_product(encoded_test[i], encoded_train[j])**2\n",
    "    \n",
    "    return K_train, K_test\n",
    "\n",
    "def total_kernels(X_train: np.ndarray, X_test: np.ndarray,\n",
    "                      encoding_names: List[str] = None, n_layers: int = 2,\n",
    "                      random_state: int = 42, verbose: bool = True\n",
    "                      ) -> Dict[str, Tuple[np.ndarray, np.ndarray]]:\n",
    "    if encoding_names is None:\n",
    "        encoding_names = list(ENCODING_REGISTER.keys())\n",
    "    results = {}\n",
    "    for name in encoding_names:\n",
    "        try:\n",
    "            K_train, K_test = kernel_matrix(\n",
    "                X_train, X_test, name, n_layers, \n",
    "                random_state=random_state, verbose=verbose\n",
    "            )\n",
    "            results[name] = (K_train, K_test)\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"  Error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_available_encodings() -> List[str]:\n",
    "    return list(ENCODING_REGISTER.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87160210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Skipped: File not found: C:\\Users\\Dao Duy Tung\\Documents\\Python\\newbie\\QuantumLab\\ML for beginner\\Kernel Discovery\\pima-indians-diabete.csv\n",
      "  Skipped: File not found: C:\\Users\\Dao Duy Tung\\Documents\\Python\\newbie\\QuantumLab\\ML for beginner\\Kernel Discovery\\BankNote_Authentication.csv\n",
      "  Skipped: File not found: C:\\Users\\Dao Duy Tung\\Documents\\Python\\newbie\\QuantumLab\\ML for beginner\\Kernel Discovery\\haberman.csv\n",
      "\n",
      "Iris dataset: Train (80, 4), Test (20, 4)\n",
      "Available encodings: ['YZ_CX', 'HighDim', 'HZY_CZ', 'Chebyshev', 'ParamZFeatureMap', 'SeparableRX', 'HardwareEfficientRx', 'ZFeatureMap', 'ZZFeatureMap']\n",
      "Sample encoding: ZFeatureMap\n"
     ]
    }
   ],
   "source": [
    "datasets = load_datasets(max_qubits=4 ,verbose=True)\n",
    "X_train, X_test, y_train, y_test = datasets[\"Iris\"]\n",
    "\n",
    "print(f\"\\nIris dataset: Train {X_train.shape}, Test {X_test.shape}\")\n",
    "print(f\"Available encodings: {get_available_encodings()}\")\n",
    "\n",
    "print(\"Sample encoding: ZFeatureMap\")\n",
    "\n",
    "K_train, K_test = kernel_matrix(\n",
    "        X_train, X_test, \"ZFeatureMap\", n_layers=2, verbose=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb90d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Circle dataset: Train (80, 2), Test (20, 2)\n",
      "\n",
      "Moons dataset: Train (80, 2), Test (20, 2)\n",
      "\n",
      "Iris dataset: Train (80, 4), Test (20, 4)\n",
      "\n",
      "Pima dataset: Train (613, 4), Test (154, 4)\n",
      "\n",
      "Banknote dataset: Train (1097, 4), Test (275, 4)\n",
      "\n",
      "Haberman dataset: Train (244, 3), Test (61, 3)\n"
     ]
    }
   ],
   "source": [
    "datasets = load_datasets(data_dir=\"datasets\", max_qubits=4, verbose=True)\n",
    "for name, (X_tr, X_te, y_tr, y_te) in datasets.items():\n",
    "    print(f\"\\n{name} dataset: Train {X_tr.shape}, Test {X_te.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7326d",
   "metadata": {},
   "source": [
    "### Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e35b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_runs(dataset_name: str = \"Iris\", \n",
    "                                encodings: list = None,\n",
    "                                n_layers: int = 2,\n",
    "                                n_runs: int = 10,\n",
    "                                test_size: float = 0.2,\n",
    "                                random_state: int = 42,\n",
    "                                verbose: bool = True):\n",
    "    if encodings is None:\n",
    "        encodings = get_available_encodings()\n",
    "    if verbose:\n",
    "        print(f\"Dataset: {dataset_name}\")    \n",
    "    results_accumulator = {enc: {m: {\"train\": [], \"test\": []} \n",
    "                                  for m in [\"SVM\", \"KRC\"]} \n",
    "                           for enc in encodings}\n",
    "    for run in tqdm(range(n_runs)):\n",
    "        seed = random_state + run\n",
    "        datasets = load_datasets(data_dir=\"datasets\", random_state=seed, test_size=test_size, max_qubits=4, verbose=False)\n",
    "        X_train, X_test, y_train, y_test = datasets[dataset_name]\n",
    "        kernels = total_kernels(X_train, X_test, encodings, n_layers, seed, verbose=False)\n",
    "        for enc_name, (K_train, K_test) in kernels.items():\n",
    "            for model_name in [\"SVM\", \"KRC\"]:\n",
    "                result = evaluate_kernel(\n",
    "                    K_train, K_test, y_train, y_test, enc_name, model_name\n",
    "                )\n",
    "                results_accumulator[enc_name][model_name][\"train\"].append(result.train_accuracy)\n",
    "                results_accumulator[enc_name][model_name][\"test\"].append(result.test_accuracy)\n",
    "    all_results = {}\n",
    "    for enc_name in encodings:\n",
    "        enc_results = []\n",
    "        for model_name in [\"SVM\", \"KRC\"]:\n",
    "            train_scores = results_accumulator[enc_name][model_name][\"train\"]\n",
    "            test_scores = results_accumulator[enc_name][model_name][\"test\"]\n",
    "            enc_results.append(KernelEvaluation(\n",
    "                model_name=model_name,\n",
    "                encoding_name=enc_name,\n",
    "                train_accuracy=np.mean(train_scores),\n",
    "                test_accuracy=np.mean(test_scores),\n",
    "                train_std=np.std(train_scores),\n",
    "                test_std=np.std(test_scores)\n",
    "            ))\n",
    "        all_results[enc_name] = enc_results\n",
    "    \n",
    "    return {\"results\": all_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b3aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(all_results):\n",
    "    print(f\"{'Encoding':<22} {'Model':<6} {'Train':<18} {'Test':<18}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    best_test_acc = 0\n",
    "    best_config = None\n",
    "    \n",
    "    for encoding_name, results in all_results.items():\n",
    "        for r in results:\n",
    "            train_str = f\"{r.train_accuracy:.4f} ± {r.train_std:.4f}\"\n",
    "            test_str = f\"{r.test_accuracy:.4f} ± {r.test_std:.4f}\"\n",
    "            print(f\"{r.encoding_name:<22} {r.model_name:<6} {train_str:<18} {test_str:<18}\")\n",
    "            if r.test_accuracy > best_test_acc:\n",
    "                best_test_acc = r.test_accuracy\n",
    "                best_config = r\n",
    "    \n",
    "    print(\"-\" * 75)\n",
    "    print(f\"Best: {best_config.encoding_name} + {best_config.model_name} = {best_test_acc:.4f} ± {best_config.test_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3185d4",
   "metadata": {},
   "source": [
    "## Accuracy Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce2002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(all_results):\n",
    "    encodings = list(all_results.keys())\n",
    "    models = [\"SVM\", \"KRC\"]\n",
    "    \n",
    "    test_accs = {m: [] for m in models}\n",
    "    test_stds = {m: [] for m in models}\n",
    "    \n",
    "    for enc in encodings:\n",
    "        for r in all_results[enc]:\n",
    "            test_accs[r.model_name].append(r.test_accuracy)\n",
    "            test_stds[r.model_name].append(r.test_std)\n",
    "    \n",
    "    x = np.arange(len(encodings))\n",
    "    width = 0.25\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        ax.bar(x + i*width, test_accs[model], width, \n",
    "               yerr=test_stds[model], label=model, capsize=3)\n",
    "    \n",
    "    ax.set_ylabel('Test Accuracy')\n",
    "    ax.set_xticks(x + width)\n",
    "    ax.set_xticklabels(encodings, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.set_ylim([0, 1.05])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a77303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_summary_table(all_dataset_results: Dict[str, Dict], \n",
    "                         model_name: str = \"SVM\") -> pd.DataFrame:\n",
    "    encodings = list(ENCODING_REGISTER.keys())\n",
    "    \n",
    "    table_data = []\n",
    "    for dataset_name, result_dict in all_dataset_results.items():\n",
    "        row = {\"Dataset\": dataset_name}\n",
    "        results = result_dict[\"results\"]\n",
    "        \n",
    "        for enc_name in encodings:\n",
    "            if enc_name in results:\n",
    "                for r in results[enc_name]:\n",
    "                    if r.model_name == model_name:\n",
    "                        row[enc_name] = f\"{r.test_accuracy:.4f}\"\n",
    "                        break\n",
    "            else:\n",
    "                row[enc_name] = \"-\"\n",
    "        \n",
    "        table_data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(table_data)\n",
    "    df = df.set_index(\"Dataset\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac238f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Dataset: Circle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Dataset: Moons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Dataset: Iris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Dataset: Pima\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:04<00:00,  6.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Dataset: Banknote\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:53<02:00, 17.14s/it]"
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "\n",
    "for dataset_name in [\"Circle\", \"Moons\", \"Iris\", \"Pima\", \"Banknote\", \"Haberman\"]:\n",
    "    print('-'*60)\n",
    "    \n",
    "    result = total_runs(\n",
    "        dataset_name=dataset_name,\n",
    "        n_layers=2,\n",
    "        n_runs=10,\n",
    "        random_state=42,\n",
    "        verbose=True\n",
    "    )\n",
    "    all_results[dataset_name] = result\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"SUMMARY TABLE (Test Accuracy - SVM)\")\n",
    "print(\"-\"*80)\n",
    "df_svm = create_summary_table(all_results, model_name=\"SVM\")\n",
    "print(df_svm.to_string())\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"SUMMARY TABLE (Test Accuracy - KRC)\")\n",
    "print(\"-\"*80)\n",
    "df_krc = create_summary_table(all_results, model_name=\"KRC\")\n",
    "print(df_krc.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854a87f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_29087\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_29087_level0_col0\" class=\"col_heading level0 col0\" >Dataset</th>\n",
       "      <th id=\"T_29087_level0_col1\" class=\"col_heading level0 col1\" >Best_Kernel</th>\n",
       "      <th id=\"T_29087_level0_col2\" class=\"col_heading level0 col2\" >Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_29087_row0_col0\" class=\"data row0 col0\" >Circle</td>\n",
       "      <td id=\"T_29087_row0_col1\" class=\"data row0 col1\" >ZFeatureMap</td>\n",
       "      <td id=\"T_29087_row0_col2\" class=\"data row0 col2\" >0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29087_row1_col0\" class=\"data row1 col0\" >Moons</td>\n",
       "      <td id=\"T_29087_row1_col1\" class=\"data row1 col1\" >HighDim</td>\n",
       "      <td id=\"T_29087_row1_col2\" class=\"data row1 col2\" >0.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29087_row2_col0\" class=\"data row2 col0\" >Iris</td>\n",
       "      <td id=\"T_29087_row2_col1\" class=\"data row2 col1\" >HighDim</td>\n",
       "      <td id=\"T_29087_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29087_row3_col0\" class=\"data row3 col0\" >Pima</td>\n",
       "      <td id=\"T_29087_row3_col1\" class=\"data row3 col1\" >ZFeatureMap</td>\n",
       "      <td id=\"T_29087_row3_col2\" class=\"data row3 col2\" >0.754545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29087_row4_col0\" class=\"data row4 col0\" >Banknote</td>\n",
       "      <td id=\"T_29087_row4_col1\" class=\"data row4 col1\" >HardwareEfficientRx</td>\n",
       "      <td id=\"T_29087_row4_col2\" class=\"data row4 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_29087_row5_col0\" class=\"data row5 col0\" >Haberman</td>\n",
       "      <td id=\"T_29087_row5_col1\" class=\"data row5 col1\" >ZFeatureMap</td>\n",
       "      <td id=\"T_29087_row5_col2\" class=\"data row5 col2\" >0.750820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x268ae0c68c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_dataframe(all_dataset_results: Dict[str, Dict], \n",
    "                          model_name: str = \"SVM\") -> pd.DataFrame:\n",
    "\n",
    "    encodings = list(ENCODING_REGISTER.keys())\n",
    "    \n",
    "    table_data = []\n",
    "    for dataset_name, result_dict in all_dataset_results.items():\n",
    "        results = result_dict[\"results\"]\n",
    "        \n",
    "        best_acc = 0\n",
    "        best_kernel = None\n",
    "        \n",
    "        for enc_name in encodings:\n",
    "            if enc_name in results:\n",
    "                for r in results[enc_name]:\n",
    "                    if r.model_name == model_name:\n",
    "                        if r.test_accuracy > best_acc:\n",
    "                            best_acc = r.test_accuracy\n",
    "                            best_kernel = enc_name\n",
    "                        break\n",
    "        \n",
    "        table_data.append({\n",
    "            \"Dataset\": dataset_name,\n",
    "            \"Best_Kernel\": best_kernel,\n",
    "            \"Test Accuracy\": best_acc\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(table_data)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_best = label_dataframe(all_results, model_name=\"SVM\")\n",
    "df_best.style.hide(axis='index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

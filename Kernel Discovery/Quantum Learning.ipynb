{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3c2d09",
   "metadata": {},
   "source": [
    "# Quantum Learning Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca71dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "qml_path = (Path.cwd() / \"../../QML\").resolve()\n",
    "sys.path.insert(0, str(qml_path))\n",
    "\n",
    "from Qsun.Qkernels import *\n",
    "from Qsun.Qgates import *\n",
    "from Qsun.Qmeas import *\n",
    "from Qsun.Qcircuit import *\n",
    "from Qsun.Qwave import *\n",
    "from Qsun.Qencodes import *\n",
    "from Qsun.Qdata import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.load_datasets import *\n",
    "from src.kernel_evaluation import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804dee3f",
   "metadata": {},
   "source": [
    "### Loading 9 ansatzes from Qencodes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb087c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING_REGISTER = {\n",
    "    \"YZ_CX\": {\n",
    "        \"fn\": YZ_CX_encode,\n",
    "        \"has_params\": True,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"HighDim\": {\n",
    "        \"fn\": HighDim_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": False,\n",
    "    },\n",
    "    \"HZY_CZ\": {\n",
    "        \"fn\": HZY_CZ_encode,\n",
    "        \"has_params\": True,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"Chebyshev\": {\n",
    "        \"fn\": Chebyshev_encode,\n",
    "        \"has_params\": True,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"ParamZFeatureMap\": {\n",
    "        \"fn\": ParamZFeatureMap_encode,\n",
    "        \"has_params\": True,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"SeparableRX\": {\n",
    "        \"fn\": SeparableRXEncoding_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": False,\n",
    "    },\n",
    "    \"HardwareEfficientRx\": {\n",
    "        \"fn\": HardwareEfficientEmbeddingRx_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"ZFeatureMap\": {\n",
    "        \"fn\": ZFeatureMap_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"ZZFeatureMap\": {\n",
    "        \"fn\": ZZFeatureMap_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "}\n",
    "\n",
    "def encode_sample(sample: np.ndarray, encoding_name: str, n_layers: int = 2, \n",
    "                  params: np.ndarray = None):\n",
    "    if encoding_name not in ENCODING_REGISTER:\n",
    "        raise ValueError(f\"Unknown encoding: {encoding_name}\")\n",
    "    config = ENCODING_REGISTER[encoding_name]\n",
    "    fn = config[\"fn\"]\n",
    "    if encoding_name == \"YZ_CX\":\n",
    "        return fn(sample, params=params, n_layers=n_layers)\n",
    "    elif encoding_name == \"HZY_CZ\":\n",
    "        return fn(sample, params=params, n_layers=n_layers)\n",
    "    elif encoding_name == \"Chebyshev\":\n",
    "        return fn(sample, params=params, n_layers=n_layers)\n",
    "    elif encoding_name == \"ParamZFeatureMap\":\n",
    "        return fn(sample, params=params, n_layers=n_layers)\n",
    "    elif encoding_name == \"HardwareEfficientRx\":\n",
    "        return fn(sample, n_layers=n_layers)\n",
    "    elif encoding_name == \"ZFeatureMap\":\n",
    "        return fn(sample, n_layers=n_layers)\n",
    "    elif encoding_name == \"ZZFeatureMap\":\n",
    "        return fn(sample, n_layers=n_layers)\n",
    "    elif encoding_name == \"HighDim\":\n",
    "        return fn(sample)\n",
    "    elif encoding_name == \"SeparableRX\":\n",
    "        return fn(sample)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown encoding: {encoding_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4169a0d2",
   "metadata": {},
   "source": [
    "### Quantum Embedding Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad72be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_matrix(X_train, X_test,\n",
    "                encoding_name, n_layers=2,\n",
    "                params=None, random_state=42):\n",
    "    n_train = X_train.shape[0]\n",
    "    n_test = X_test.shape[0]\n",
    "    encoded_train = []\n",
    "    for i in range(n_train):\n",
    "        state = encode_sample(X_train[i], encoding_name, n_layers, params)\n",
    "        encoded_train.append(state)\n",
    "    encoded_test = []\n",
    "    for i in range(n_test):\n",
    "        state = encode_sample(X_test[i], encoding_name, n_layers, params)\n",
    "        encoded_test.append(state)\n",
    "    K_train = np.zeros((n_train, n_train))\n",
    "    for i in range(n_train):\n",
    "        for j in range(i, n_train):\n",
    "            k_ij = state_product(encoded_train[i], encoded_train[j])**2\n",
    "            K_train[i, j] = k_ij\n",
    "            K_train[j, i] = k_ij\n",
    "    K_test = np.zeros((n_test, n_train))\n",
    "    for i in range(n_test):\n",
    "        for j in range(n_train):\n",
    "            K_test[i, j] = state_product(encoded_test[i], encoded_train[j])**2\n",
    "    \n",
    "    return K_train, K_test\n",
    "\n",
    "def total_kernels(X_train, X_test,\n",
    "                encoding_names=None, n_layers=2,\n",
    "                random_state=42):\n",
    "    if encoding_names is None:\n",
    "        encoding_names = list(ENCODING_REGISTER.keys())\n",
    "    results = {}\n",
    "    for name in encoding_names:\n",
    "        try:\n",
    "            K_train, K_test = kernel_matrix(\n",
    "                X_train, X_test, name, n_layers, \n",
    "                random_state=random_state)\n",
    "            results[name] = (K_train, K_test)\n",
    "        except Exception as e:\n",
    "                print(f\"  Error: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_available_encodings():\n",
    "    return list(ENCODING_REGISTER.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87160210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iris dataset: Train (80, 4), Test (20, 4)\n",
      "Available encodings: ['YZ_CX', 'HighDim', 'HZY_CZ', 'Chebyshev', 'ParamZFeatureMap', 'SeparableRX', 'HardwareEfficientRx', 'ZFeatureMap', 'ZZFeatureMap']\n",
      "Sample encoding: ZFeatureMap\n"
     ]
    }
   ],
   "source": [
    "datasets = load_datasets(\n",
    "    data_dir=\"datasets\", \n",
    "    max_qubit=4, \n",
    "    include_variants=True \n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = datasets[\"Iris\"]\n",
    "\n",
    "print(f\"\\nIris dataset: Train {X_train.shape}, Test {X_test.shape}\")\n",
    "print(f\"Available encodings: {get_available_encodings()}\")\n",
    "\n",
    "print(\"Sample encoding: ZFeatureMap\")\n",
    "\n",
    "K_train, K_test = kernel_matrix(\n",
    "        X_train, X_test, \"ZFeatureMap\", n_layers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcb90d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blobs_F2C2 dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "Blobs_F2C3 dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "Blobs_F2C4 dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "Blobs_F4C2 dataset: Train (160, 4), Test (40, 4)\n",
      "\n",
      "Blobs_F4C3 dataset: Train (160, 4), Test (40, 4)\n",
      "\n",
      "Blobs_F4C4 dataset: Train (160, 4), Test (40, 4)\n",
      "\n",
      "Blobs_F2C2_std3 dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "Blobs_F2C2_std10 dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "Blobs_F4C2_std3 dataset: Train (160, 4), Test (40, 4)\n",
      "\n",
      "Blobs_F4C2_std10 dataset: Train (160, 4), Test (40, 4)\n",
      "\n",
      "Circle_n05_f5 dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "Circle_n10_f5 dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "Circle_n15_f5 dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "Circle_n10_f3 dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "Circle_n10_f8 dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "Moons_n05 dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "Moons_n10 dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "Moons_n15 dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "Moons_n25 dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "XOR dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "Spiral dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "Checkerboard_2x2 dataset: Train (160, 2), Test (40, 2)\n",
      "\n",
      "Iris dataset: Train (80, 4), Test (20, 4)\n",
      "\n",
      "Wine dataset: Train (104, 4), Test (26, 4)\n",
      "\n",
      "BreastCancer dataset: Train (455, 4), Test (114, 4)\n",
      "\n",
      "Pima dataset: Train (613, 4), Test (154, 4)\n",
      "\n",
      "Banknote dataset: Train (1097, 4), Test (275, 4)\n",
      "\n",
      "Haberman dataset: Train (244, 3), Test (61, 3)\n"
     ]
    }
   ],
   "source": [
    "datasets = load_datasets(\n",
    "    data_dir=\"datasets\", \n",
    "    max_qubit=4, \n",
    "    include_variants=True  \n",
    ")\n",
    "for name, (X_tr, X_te, y_tr, y_te) in datasets.items():\n",
    "    print(f\"\\n{name} dataset: Train {X_tr.shape}, Test {X_te.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7326d",
   "metadata": {},
   "source": [
    "### Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e35b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_runs(dataset_name=\"Iris\", \n",
    "               encodings=None,\n",
    "               n_layers=2,\n",
    "               n_runs=10,\n",
    "               test_size=0.2,\n",
    "               random_state=42,\n",
    "               include_variants=True):\n",
    "    if encodings is None:\n",
    "        encodings = get_available_encodings()\n",
    "    print(f\"Dataset: {dataset_name}\")    \n",
    "    \n",
    "    results_accumulator = {enc: {m: {\"train\": [], \"test\": []} \n",
    "                                  for m in [\"SVM\"]} \n",
    "                           for enc in encodings}\n",
    "    \n",
    "    for run in tqdm(range(n_runs)):\n",
    "        seed = random_state + run\n",
    "        datasets = load_datasets(\n",
    "            data_dir=\"datasets\",\n",
    "            random_state=seed, \n",
    "            test_size=test_size, \n",
    "            max_qubit=4,\n",
    "            include_variants=include_variants\n",
    "        )\n",
    "        X_train, X_test, y_train, y_test = datasets[dataset_name]\n",
    "        kernels = total_kernels(X_train, X_test, encodings, n_layers, seed)\n",
    "        \n",
    "        for enc_name, (K_train, K_test) in kernels.items():\n",
    "            for model_name in [\"SVM\"]:\n",
    "                result = evaluate_kernel(\n",
    "                    K_train, K_test, y_train, y_test, enc_name, model_name\n",
    "                )\n",
    "                results_accumulator[enc_name][model_name][\"train\"].append(result.train_accuracy)\n",
    "                results_accumulator[enc_name][model_name][\"test\"].append(result.test_accuracy)\n",
    "    \n",
    "    all_results = {}\n",
    "    for enc_name in encodings:\n",
    "        enc_results = []\n",
    "        for model_name in [\"SVM\"]:\n",
    "            train_scores = results_accumulator[enc_name][model_name][\"train\"]\n",
    "            test_scores = results_accumulator[enc_name][model_name][\"test\"]\n",
    "            enc_results.append(KernelEvaluation(\n",
    "                model_name=model_name,\n",
    "                encoding_name=enc_name,\n",
    "                train_accuracy=np.mean(train_scores),\n",
    "                test_accuracy=np.mean(test_scores),\n",
    "                train_std=np.std(train_scores),\n",
    "                test_std=np.std(test_scores)\n",
    "            ))\n",
    "        all_results[enc_name] = enc_results\n",
    "    \n",
    "    return {\"results\": all_results}\n",
    "\n",
    "\n",
    "def run_all_datasets(encodings=None, n_layers=2, n_runs=10, \n",
    "                     test_size=0.2, random_state=42, include_variants=True):\n",
    "    \"\"\"Run experiments on all available datasets.\"\"\"\n",
    "    datasets = load_datasets(\n",
    "        data_dir=\"datasets\", \n",
    "        max_qubit=4, \n",
    "        include_variants=include_variants\n",
    "    )\n",
    "    \n",
    "    all_results = {}\n",
    "    dataset_names = list(datasets.keys())\n",
    "    \n",
    "    print(f\"Total datasets to process: {len(dataset_names)}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for dataset_name in dataset_names:\n",
    "        result = total_runs(\n",
    "            dataset_name=dataset_name,\n",
    "            encodings=encodings,\n",
    "            n_layers=n_layers,\n",
    "            n_runs=n_runs,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            include_variants=include_variants\n",
    "        )\n",
    "        all_results[dataset_name] = result\n",
    "        print()\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34b3aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(all_results):\n",
    "    \"\"\"Summary for single dataset results.\"\"\"\n",
    "    print(f\"{'Encoding':<22} {'Model':<6} {'Train':<18} {'Test':<18}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    best_test_acc = 0\n",
    "    best_config = None\n",
    "    \n",
    "    for encoding_name, results in all_results.items():\n",
    "        for r in results:\n",
    "            train_str = f\"{r.train_accuracy:.4f} ± {r.train_std:.4f}\"\n",
    "            test_str = f\"{r.test_accuracy:.4f} ± {r.test_std:.4f}\"\n",
    "            print(f\"{r.encoding_name:<22} {r.model_name:<6} {train_str:<18} {test_str:<18}\")\n",
    "            if r.test_accuracy > best_test_acc:\n",
    "                best_test_acc = r.test_accuracy\n",
    "                best_config = r\n",
    "    \n",
    "    print(\"-\" * 75)\n",
    "    print(f\"Best: {best_config.encoding_name} + {best_config.model_name} = {best_test_acc:.4f} ± {best_config.test_std:.4f}\")\n",
    "\n",
    "\n",
    "def summary_all_datasets(all_dataset_results, model_name=\"SVM\"):\n",
    "    \"\"\"Summary table showing best kernel for each dataset.\"\"\"\n",
    "    print(f\"{'Dataset':<25} {'Best Kernel':<22} {'Test Accuracy':<18}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    summary_data = []\n",
    "    \n",
    "    for dataset_name, result_dict in all_dataset_results.items():\n",
    "        results = result_dict[\"results\"]\n",
    "        \n",
    "        best_acc = 0\n",
    "        best_kernel = None\n",
    "        best_std = 0\n",
    "        \n",
    "        for enc_name, enc_results in results.items():\n",
    "            for r in enc_results:\n",
    "                if r.model_name == model_name and r.test_accuracy > best_acc:\n",
    "                    best_acc = r.test_accuracy\n",
    "                    best_kernel = enc_name\n",
    "                    best_std = r.test_std\n",
    "        \n",
    "        summary_data.append({\n",
    "            \"Dataset\": dataset_name,\n",
    "            \"Best_Kernel\": best_kernel,\n",
    "            \"Accuracy\": best_acc,\n",
    "            \"Std\": best_std\n",
    "        })\n",
    "        \n",
    "        acc_str = f\"{best_acc:.4f} ± {best_std:.4f}\"\n",
    "        print(f\"{dataset_name:<25} {best_kernel:<22} {acc_str:<18}\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Total: {len(all_dataset_results)} datasets\")\n",
    "    \n",
    "    return pd.DataFrame(summary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0210db26",
   "metadata": {},
   "source": [
    "# Table summary for accuracy corresponds to all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92a77303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_table(all_dataset_results, \n",
    "                         model_name=\"SVM\",\n",
    "                         show_std=False) -> pd.DataFrame:\n",
    "    encodings = list(ENCODING_REGISTER.keys())\n",
    "    \n",
    "    table_data = []\n",
    "    for dataset_name, result_dict in all_dataset_results.items():\n",
    "        row = {\"Dataset\": dataset_name}\n",
    "        results = result_dict[\"results\"]\n",
    "        \n",
    "        for enc_name in encodings:\n",
    "            if enc_name in results:\n",
    "                for r in results[enc_name]:\n",
    "                    if r.model_name == model_name:\n",
    "                        if show_std:\n",
    "                            row[enc_name] = f\"{r.test_accuracy:.4f} ± {r.test_std:.4f}\"\n",
    "                        else:\n",
    "                            row[enc_name] = r.test_accuracy\n",
    "                        break\n",
    "            else:\n",
    "                row[enc_name] = None if not show_std else \"-\"\n",
    "        \n",
    "        table_data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(table_data)\n",
    "    df = df.set_index(\"Dataset\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac238f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total datasets: 28\n",
      "============================================================\n",
      "\n",
      "Processing: Blobs_F2C2\n",
      "------------------------------------------------------------\n",
      "Dataset: Blobs_F2C2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Blobs_F2C3\n",
      "------------------------------------------------------------\n",
      "Dataset: Blobs_F2C3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Blobs_F2C4\n",
      "------------------------------------------------------------\n",
      "Dataset: Blobs_F2C4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Blobs_F4C2\n",
      "------------------------------------------------------------\n",
      "Dataset: Blobs_F4C2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Blobs_F4C3\n",
      "------------------------------------------------------------\n",
      "Dataset: Blobs_F4C3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Blobs_F4C4\n",
      "------------------------------------------------------------\n",
      "Dataset: Blobs_F4C4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Blobs_F2C2_std3\n",
      "------------------------------------------------------------\n",
      "Dataset: Blobs_F2C2_std3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Blobs_F2C2_std10\n",
      "------------------------------------------------------------\n",
      "Dataset: Blobs_F2C2_std10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Blobs_F4C2_std3\n",
      "------------------------------------------------------------\n",
      "Dataset: Blobs_F4C2_std3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Blobs_F4C2_std10\n",
      "------------------------------------------------------------\n",
      "Dataset: Blobs_F4C2_std10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Circle_n05_f5\n",
      "------------------------------------------------------------\n",
      "Dataset: Circle_n05_f5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Circle_n10_f5\n",
      "------------------------------------------------------------\n",
      "Dataset: Circle_n10_f5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Circle_n15_f5\n",
      "------------------------------------------------------------\n",
      "Dataset: Circle_n15_f5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Circle_n10_f3\n",
      "------------------------------------------------------------\n",
      "Dataset: Circle_n10_f3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Circle_n10_f8\n",
      "------------------------------------------------------------\n",
      "Dataset: Circle_n10_f8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Moons_n05\n",
      "------------------------------------------------------------\n",
      "Dataset: Moons_n05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Moons_n10\n",
      "------------------------------------------------------------\n",
      "Dataset: Moons_n10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Moons_n15\n",
      "------------------------------------------------------------\n",
      "Dataset: Moons_n15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Moons_n25\n",
      "------------------------------------------------------------\n",
      "Dataset: Moons_n25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: XOR\n",
      "------------------------------------------------------------\n",
      "Dataset: XOR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Spiral\n",
      "------------------------------------------------------------\n",
      "Dataset: Spiral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Checkerboard_2x2\n",
      "------------------------------------------------------------\n",
      "Dataset: Checkerboard_2x2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Iris\n",
      "------------------------------------------------------------\n",
      "Dataset: Iris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Wine\n",
      "------------------------------------------------------------\n",
      "Dataset: Wine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: BreastCancer\n",
      "------------------------------------------------------------\n",
      "Dataset: BreastCancer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Pima\n",
      "------------------------------------------------------------\n",
      "Dataset: Pima\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:44<00:00,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Banknote\n",
      "------------------------------------------------------------\n",
      "Dataset: Banknote\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:59<00:00, 11.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Haberman\n",
      "------------------------------------------------------------\n",
      "Dataset: Haberman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY TABLE (Test Accuracy - SVM)\n",
      "================================================================================\n",
      "                     YZ_CX   HighDim    HZY_CZ  Chebyshev  ParamZFeatureMap  SeparableRX  HardwareEfficientRx  ZFeatureMap  ZZFeatureMap\n",
      "Dataset                                                                                                                                 \n",
      "Blobs_F2C2        0.542500  0.995000  1.000000   0.652500          0.837500     0.997500             0.997500     0.985000      0.960000\n",
      "Blobs_F2C3        0.322500  1.000000  1.000000   0.487500          0.702500     1.000000             0.995000     1.000000      0.995000\n",
      "Blobs_F2C4        0.265000  0.995000  1.000000   0.370000          0.587500     0.997500             0.997500     0.997500      0.987500\n",
      "Blobs_F4C2        0.452500  1.000000  1.000000   0.657500          0.912500     1.000000             1.000000     0.997500      0.987500\n",
      "Blobs_F4C3        0.340000  1.000000  1.000000   0.410000          0.750000     1.000000             1.000000     1.000000      0.995000\n",
      "Blobs_F4C4        0.242500  1.000000  1.000000   0.335000          0.735000     1.000000             1.000000     1.000000      0.997500\n",
      "Blobs_F2C2_std3   0.512500  0.985000  1.000000   0.652500          0.847500     1.000000             0.997500     0.995000      0.980000\n",
      "Blobs_F2C2_std10  0.437500  0.992500  0.997500   0.650000          0.715000     0.995000             0.987500     0.912500      0.902500\n",
      "Blobs_F4C2_std3   0.545000  0.997500  1.000000   0.577500          0.950000     1.000000             1.000000     0.997500      0.995000\n",
      "Blobs_F4C2_std10  0.477500  1.000000  1.000000   0.605000          0.797500     1.000000             1.000000     0.950000      0.940000\n",
      "Circle_n05_f5     0.520000  0.982500  0.985000   0.567500          0.547500     1.000000             1.000000     1.000000      0.772500\n",
      "Circle_n10_f5     0.432500  0.940000  0.967500   0.560000          0.570000     0.992500             0.992500     0.992500      0.802500\n",
      "Circle_n15_f5     0.487500  0.900000  0.882500   0.590000          0.627500     0.922500             0.930000     0.925000      0.815000\n",
      "Circle_n10_f3     0.510000  0.997500  1.000000   0.615000          0.612500     1.000000             1.000000     1.000000      0.950000\n",
      "Circle_n10_f8     0.495000  0.552500  0.737500   0.500000          0.497500     0.787500             0.795000     0.800000      0.572500\n",
      "Moons_n05         0.580000  0.990000  0.912500   0.577500          0.597500     0.812500             0.857500     0.977500      0.820000\n",
      "Moons_n10         0.527500  0.985000  0.870000   0.540000          0.582500     0.792500             0.857500     0.942500      0.817500\n",
      "Moons_n15         0.472500  0.972500  0.827500   0.557500          0.567500     0.787500             0.855000     0.852500      0.762500\n",
      "Moons_n25         0.525000  0.912500  0.827500   0.555000          0.602500     0.785000             0.840000     0.752500      0.707500\n",
      "XOR               0.485000  0.927500  0.932500   0.500000          0.527500     0.932500             0.925000     0.570000      0.797500\n",
      "Spiral            0.485000  0.937500  0.882500   0.520000          0.550000     0.787500             0.552500     0.787500      0.752500\n",
      "Checkerboard_2x2  0.530000  0.920000  0.917500   0.532500          0.517500     0.855000             0.895000     0.480000      0.747500\n",
      "Iris              0.505000  1.000000  1.000000   0.520000          0.845000     1.000000             1.000000     0.960000      0.860000\n",
      "Wine              0.473077  0.957692  0.969231   0.553846          0.730769     0.965385             0.980769     0.784615      0.696154\n",
      "BreastCancer      0.600877  0.939474  0.920175   0.612281          0.800877     0.944737             0.943860     0.942105      0.935965\n",
      "Pima              0.625974  0.748052  0.737662   0.618831          0.658442     0.745455             0.747403     0.754545      0.709091\n",
      "Banknote          0.523636  0.993818  0.987636   0.535636          0.583636     0.998545             1.000000     0.966182      0.989091\n",
      "Haberman          0.737705  0.732787  0.716393   0.737705          0.734426     0.716393             0.734426     0.750820      0.736066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = load_datasets(\n",
    "    data_dir=\"datasets\", \n",
    "    max_qubit=4,\n",
    "    include_variants=True\n",
    ")\n",
    "\n",
    "print(f\"Total datasets: {len(datasets)}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for dataset_name in datasets.keys():\n",
    "    print(f\"\\nProcessing: {dataset_name}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    result = total_runs(\n",
    "        dataset_name=dataset_name,\n",
    "        n_layers=2,\n",
    "        n_runs=10,\n",
    "        random_state=42,\n",
    "        include_variants=True\n",
    "    )\n",
    "    all_results[dataset_name] = result\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY TABLE (Test Accuracy - SVM)\")\n",
    "print(\"=\" * 80)\n",
    "df_svm = create_summary_table(all_results, model_name=\"SVM\", show_std=False)\n",
    "print(df_svm.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "854a87f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1-A: Single Best Kernel\n",
      "                          Best_Kernel  Accuracy\n",
      "Dataset                                        \n",
      "Blobs_F2C2                     HZY_CZ  1.000000\n",
      "Blobs_F2C3                    HighDim  1.000000\n",
      "Blobs_F2C4                     HZY_CZ  1.000000\n",
      "Blobs_F4C2                    HighDim  1.000000\n",
      "Blobs_F4C3                    HighDim  1.000000\n",
      "Blobs_F4C4                    HighDim  1.000000\n",
      "Blobs_F2C2_std3                HZY_CZ  1.000000\n",
      "Blobs_F2C2_std10               HZY_CZ  0.997500\n",
      "Blobs_F4C2_std3                HZY_CZ  1.000000\n",
      "Blobs_F4C2_std10              HighDim  1.000000\n",
      "Circle_n05_f5             SeparableRX  1.000000\n",
      "Circle_n10_f5             SeparableRX  0.992500\n",
      "Circle_n15_f5     HardwareEfficientRx  0.930000\n",
      "Circle_n10_f3                  HZY_CZ  1.000000\n",
      "Circle_n10_f8             ZFeatureMap  0.800000\n",
      "Moons_n05                     HighDim  0.990000\n",
      "Moons_n10                     HighDim  0.985000\n",
      "Moons_n15                     HighDim  0.972500\n",
      "Moons_n25                     HighDim  0.912500\n",
      "XOR                            HZY_CZ  0.932500\n",
      "Spiral                        HighDim  0.937500\n",
      "Checkerboard_2x2              HighDim  0.920000\n",
      "Iris                          HighDim  1.000000\n",
      "Wine              HardwareEfficientRx  0.980769\n",
      "BreastCancer              SeparableRX  0.944737\n",
      "Pima                      ZFeatureMap  0.754545\n",
      "Banknote          HardwareEfficientRx  1.000000\n",
      "Haberman                  ZFeatureMap  0.750820\n",
      "\n",
      "Task 1-A samples: 28\n",
      "Task 1-B samples: 95\n",
      "\n",
      "Task 1-B: All Tied Best Kernels\n",
      "                    Best_Kernel  Accuracy\n",
      "Dataset                                  \n",
      "Blobs_F2C2              HighDim  0.995000\n",
      "Blobs_F2C2               HZY_CZ  1.000000\n",
      "Blobs_F2C2          SeparableRX  0.997500\n",
      "Blobs_F2C2  HardwareEfficientRx  0.997500\n",
      "Blobs_F2C3              HighDim  1.000000\n",
      "...                         ...       ...\n",
      "Pima                ZFeatureMap  0.754545\n",
      "Banknote                HighDim  0.993818\n",
      "Banknote            SeparableRX  0.998545\n",
      "Banknote    HardwareEfficientRx  1.000000\n",
      "Haberman            ZFeatureMap  0.750820\n",
      "\n",
      "[95 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def label_dataframe(all_dataset_results, \n",
    "                    model_name=\"SVM\",\n",
    "                    threshold=0.01):\n",
    "    encodings = list(ENCODING_REGISTER.keys())\n",
    "    \n",
    "    table_data = []\n",
    "    tied_data = []\n",
    "    \n",
    "    for dataset_name, result_dict in all_dataset_results.items():\n",
    "        results = result_dict[\"results\"]\n",
    "        \n",
    "        kernel_accs = {}\n",
    "        for enc_name in encodings:\n",
    "            if enc_name in results:\n",
    "                for r in results[enc_name]:\n",
    "                    if r.model_name == model_name:\n",
    "                        kernel_accs[enc_name] = r.test_accuracy\n",
    "                        break\n",
    "        \n",
    "        if not kernel_accs:\n",
    "            continue\n",
    "            \n",
    "        # Find best\n",
    "        best_acc = max(kernel_accs.values())\n",
    "        best_kernel = max(kernel_accs, key=kernel_accs.get)\n",
    "        \n",
    "        table_data.append({\n",
    "            \"Dataset\": dataset_name,\n",
    "            \"Best_Kernel\": best_kernel,\n",
    "            \"Accuracy\": best_acc\n",
    "        })\n",
    "        \n",
    "        # Find tied kernels (Task 1-B)\n",
    "        if threshold is not None:\n",
    "            for enc_name, acc in kernel_accs.items():\n",
    "                if acc >= best_acc - threshold:\n",
    "                    tied_data.append({\n",
    "                        \"Dataset\": dataset_name,\n",
    "                        \"Best_Kernel\": enc_name,\n",
    "                        \"Accuracy\": acc\n",
    "                    })\n",
    "    \n",
    "    df = pd.DataFrame(table_data).set_index(\"Dataset\")\n",
    "    \n",
    "    if threshold is not None and tied_data:\n",
    "        df_tied = pd.DataFrame(tied_data).set_index(\"Dataset\")\n",
    "        return df, df_tied\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Sử dụng Task 1-A (single best)\n",
    "df_best = label_dataframe(all_results, model_name=\"SVM\", threshold=None)\n",
    "print(\"Task 1-A: Single Best Kernel\")\n",
    "print(df_best)\n",
    "\n",
    "# Sử dụng Task 1-B (tied kernels within 1% threshold)\n",
    "df_best, df_tied = label_dataframe(all_results, model_name=\"SVM\", threshold=0.01)\n",
    "print(f\"\\nTask 1-A samples: {len(df_best)}\")\n",
    "print(f\"Task 1-B samples: {len(df_tied)}\")\n",
    "print(\"\\nTask 1-B: All Tied Best Kernels\")\n",
    "print(df_tied)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

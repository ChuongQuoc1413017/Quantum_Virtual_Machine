{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b53462d",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "![Workflow Diagram](training_models.jpg)\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84579392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, \n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd1b6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOAD DATA\n",
      "======================================================================\n",
      "Datasets: 28\n",
      "Metrics: 24\n",
      "Task 1-A samples: 28\n",
      "Task 1-B samples: 95\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"LOAD DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df = pd.read_csv(\"synthesis_df.csv\", index_col=0)\n",
    "df_tied = pd.read_csv(\"task1b_labels.csv\")\n",
    "df_tied = df_tied.set_index('Dataset')\n",
    "\n",
    "metric_columns = [c for c in df.columns if c != 'Best_Kernel']\n",
    "\n",
    "print(f\"Datasets: {len(df)}\")\n",
    "print(f\"Metrics: {len(metric_columns)}\")\n",
    "print(f\"Task 1-A samples: {len(df)}\")\n",
    "print(f\"Task 1-B samples: {len(df_tied)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f847c436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers: 14\n"
     ]
    }
   ],
   "source": [
    "CLASSIFIERS = {\n",
    "    'DT': DecisionTreeClassifier(random_state=42),\n",
    "    'RF': RandomForestClassifier(n_estimators=10, random_state=42),\n",
    "    'Ensemble-GB': GradientBoostingClassifier(random_state=42),\n",
    "    'Ensemble-AB': AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(random_state=42), \n",
    "        n_estimators=50, \n",
    "        random_state=42,\n",
    "        algorithm='SAMME'\n",
    "    ),\n",
    "    'Ensemble-Bg': BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(random_state=42),\n",
    "        n_estimators=10,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'SVM-Linear': SVC(kernel='linear', random_state=42),\n",
    "    'SVM-RBF': SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42),\n",
    "    'SVM-Sigmoid': SVC(kernel='sigmoid', C=1.0, gamma='scale', random_state=42),\n",
    "    'MLP-500': MLPClassifier(hidden_layer_sizes=(500,), max_iter=1000, random_state=42),\n",
    "    'MLP-100-100-100': MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=1000, random_state=42),\n",
    "    'kNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'NearestCentroid': NearestCentroid(),\n",
    "    'NaiveBayes': GaussianNB(),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "}\n",
    "\n",
    "print(f\"Classifiers: {len(CLASSIFIERS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8093dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_task1a(X, y, classifiers, scale_features=True, desc=\"Task 1-A\"):\n",
    "    \"\"\"\n",
    "    Task 1-A: LOOCV vá»›i single best kernel\n",
    "    X: features (single metric hoáº·c all metrics)\n",
    "    y: labels (only 1 Best_Kernel)\n",
    "    \"\"\"\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    \n",
    "    loo = LeaveOneOut()\n",
    "    results = {}\n",
    "    \n",
    "    for clf_name, clf in tqdm(classifiers.items(), desc=desc):\n",
    "        scores = []\n",
    "        \n",
    "        for train_idx, test_idx in loo.split(X):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y_encoded[train_idx], y_encoded[test_idx]\n",
    "            \n",
    "            if scale_features and X.shape[1] > 1:\n",
    "                scaler = StandardScaler()\n",
    "                X_train = scaler.fit_transform(X_train)\n",
    "                X_test = scaler.transform(X_test)\n",
    "            \n",
    "            try:\n",
    "                clf_clone = clf.__class__(**clf.get_params())\n",
    "                clf_clone.fit(X_train, y_train)\n",
    "                pred = clf_clone.predict(X_test)\n",
    "                scores.append(1 if pred[0] == y_test[0] else 0)\n",
    "            except:\n",
    "                scores.append(0)\n",
    "        \n",
    "        results[clf_name] = {\n",
    "            'accuracy': np.mean(scores),\n",
    "            'std': np.std(scores),\n",
    "            'correct': sum(scores),\n",
    "            'total': len(scores)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_task1b(X, df_tied, dataset_names, classifiers, scale_features=True, desc=\"Task 1-B\"):\n",
    "    \"\"\"\n",
    "    Task 1-B: LOOCV vá»›i tied best kernels\n",
    "    Prediction Ä‘Ãºng náº¿u match Báº¤T Ká»² tied kernel nÃ o\n",
    "    \"\"\"\n",
    "    n_datasets = len(dataset_names)\n",
    "    \n",
    "    valid_kernels_lookup = {}\n",
    "    for dataset in dataset_names:\n",
    "        valid_kernels_lookup[dataset] = df_tied.loc[\n",
    "            df_tied.index == dataset, 'Best_Kernel'\n",
    "        ].tolist()\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for clf_name, clf in tqdm(classifiers.items(), desc=desc):\n",
    "        scores = []\n",
    "        \n",
    "        for test_idx, test_dataset in enumerate(dataset_names):\n",
    "            X_train_list = []\n",
    "            y_train_list = []\n",
    "            \n",
    "            for train_idx, train_dataset in enumerate(dataset_names):\n",
    "                if train_dataset == test_dataset:\n",
    "                    continue\n",
    "                \n",
    "                valid_kernels = valid_kernels_lookup[train_dataset]\n",
    "                for kernel in valid_kernels:\n",
    "                    X_train_list.append(X[train_idx])\n",
    "                    y_train_list.append(kernel)\n",
    "            \n",
    "            X_train = np.array(X_train_list)\n",
    "            y_train = np.array(y_train_list)\n",
    "            \n",
    "            # Encode\n",
    "            le = LabelEncoder()\n",
    "            y_train_encoded = le.fit_transform(y_train)\n",
    "            \n",
    "            if len(np.unique(y_train_encoded)) < 2:\n",
    "                scores.append(0)\n",
    "                continue\n",
    "            \n",
    "            if scale_features and X.shape[1] > 1:\n",
    "                scaler = StandardScaler()\n",
    "                X_train_scaled = scaler.fit_transform(X_train)\n",
    "                X_test_scaled = scaler.transform(X[test_idx:test_idx+1])\n",
    "            else:\n",
    "                X_train_scaled = X_train\n",
    "                X_test_scaled = X[test_idx:test_idx+1]\n",
    "            \n",
    "            valid_kernels_test = valid_kernels_lookup[test_dataset]\n",
    "            \n",
    "            try:\n",
    "                clf_clone = clf.__class__(**clf.get_params())\n",
    "                clf_clone.fit(X_train_scaled, y_train_encoded)\n",
    "                pred_encoded = clf_clone.predict(X_test_scaled)\n",
    "                pred_kernel = le.inverse_transform(pred_encoded)[0]\n",
    "                \n",
    "                is_correct = pred_kernel in valid_kernels_test\n",
    "                scores.append(1 if is_correct else 0)\n",
    "            except:\n",
    "                scores.append(0)\n",
    "        \n",
    "        results[clf_name] = {\n",
    "            'accuracy': np.mean(scores),\n",
    "            'std': np.std(scores),\n",
    "            'correct': sum(scores),\n",
    "            'total': n_datasets\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "186566bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = df.index.tolist()\n",
    "y = df['Best_Kernel'].values\n",
    "X_all = df[metric_columns].values  \n",
    "\n",
    "all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd2fa95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CASE 1: SINGLE METRIC - TASK 1-A\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:22<00:00,  1.61s/it]00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:23<00:00,  1.64s/it]00:22<08:39, 22.61s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:24<00:00,  1.78s/it]00:45<08:22, 22.85s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:23<00:00,  1.67s/it]01:10<08:19, 23.80s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:24<00:00,  1.75s/it]01:33<07:52, 23.64s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:12<00:00,  1.10it/s]01:58<07:34, 23.93s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:24<00:00,  1.76s/it]02:11<06:01, 20.11s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:24<00:00,  1.78s/it]02:35<06:06, 21.58s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:22<00:00,  1.58s/it]03:00<06:02, 22.63s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:21<00:00,  1.56s/it]03:22<05:37, 22.47s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:17<00:00,  1.26s/it][03:44<05:11, 22.28s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:19<00:00,  1.38s/it][04:02<04:31, 20.85s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:12<00:00,  1.10it/s][04:21<04:04, 20.38s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:16<00:00,  1.14s/it][04:34<03:18, 18.06s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:20<00:00,  1.43s/it][04:50<02:54, 17.45s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:20<00:00,  1.48s/it][05:10<02:44, 18.24s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:13<00:00,  1.02it/s][05:31<02:32, 19.01s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.31it/s][05:44<02:01, 17.42s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.31it/s][05:49<01:20, 13.45s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.73it/s][05:53<00:53, 10.68s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:15<00:00,  1.13s/it][06:01<00:39,  9.91s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:17<00:00,  1.25s/it][06:17<00:35, 11.70s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:14<00:00,  1.03s/it][06:34<00:26, 13.46s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:21<00:00,  1.53s/it][06:49<00:13, 13.76s/it]\n",
      "Single Metric Task 1-A: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [07:10<00:00, 17.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â˜… Best Single Metric (Task 1-A): l2 + RF = 0.6071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CASE 1: SINGLE METRIC - TASK 1-A\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "single_metric_task1a = []\n",
    "\n",
    "for metric in tqdm(metric_columns, desc=\"Single Metric Task 1-A\"):\n",
    "    X_single = df[[metric]].values\n",
    "    results = evaluate_task1a(X_single, y, CLASSIFIERS, scale_features=False, desc=\"\")\n",
    "    \n",
    "    for clf_name, res in results.items():\n",
    "        single_metric_task1a.append({\n",
    "            'Metric': metric,\n",
    "            'Classifier': clf_name,\n",
    "            'Accuracy': res['accuracy'],\n",
    "            'Correct': res['correct'],\n",
    "            'Total': res['total']\n",
    "        })\n",
    "\n",
    "df_single_1a = pd.DataFrame(single_metric_task1a)\n",
    "best_single_1a = df_single_1a.loc[df_single_1a['Accuracy'].idxmax()]\n",
    "print(f\"\\nâ˜… Best Single Metric (Task 1-A): {best_single_1a['Metric']} + {best_single_1a['Classifier']} = {best_single_1a['Accuracy']:.4f}\")\n",
    "\n",
    "all_results['single_metric_task1a'] = df_single_1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf1a533f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CASE 2: SINGLE METRIC - TASK 1-B\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:16<00:00,  1.21s/it]00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:21<00:00,  1.54s/it]00:16<06:30, 16.96s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:32<00:00,  2.33s/it]00:38<07:12, 19.67s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:19<00:00,  1.40s/it]01:11<08:57, 25.58s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:25<00:00,  1.85s/it]01:30<07:44, 23.23s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:07<00:00,  1.91it/s]01:56<07:39, 24.17s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:29<00:00,  2.12s/it]02:03<05:32, 18.45s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:29<00:00,  2.10s/it]02:33<06:15, 22.10s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:10<00:00,  1.32it/s]03:02<06:30, 24.40s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:28<00:00,  2.07s/it]03:13<05:01, 20.09s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:11<00:00,  1.17it/s][03:42<05:19, 22.83s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:23<00:00,  1.68s/it][03:54<04:13, 19.51s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:13<00:00,  1.07it/s][04:17<04:08, 20.72s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:13<00:00,  1.03it/s][04:31<03:22, 18.42s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:18<00:00,  1.32s/it][04:44<02:49, 16.97s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:26<00:00,  1.87s/it][05:03<02:36, 17.41s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:19<00:00,  1.37s/it][05:29<02:40, 20.05s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:07<00:00,  1.94it/s][05:48<02:18, 19.80s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:07<00:00,  1.96it/s][05:55<01:36, 16.02s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:07<00:00,  1.77it/s][06:02<01:06, 13.35s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:07<00:00,  1.94it/s][06:10<00:46, 11.72s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.56it/s][06:18<00:31, 10.37s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.65it/s][06:27<00:19,  9.96s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:21<00:00,  1.56s/it][06:35<00:09,  9.51s/it]\n",
      "Single Metric Task 1-B: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [06:57<00:00, 17.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â˜… Best Single Metric (Task 1-B): l3 + DT = 0.9286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CASE 2: SINGLE METRIC - TASK 1-B\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "single_metric_task1b = []\n",
    "\n",
    "for metric in tqdm(metric_columns, desc=\"Single Metric Task 1-B\"):\n",
    "    X_single = df[[metric]].values\n",
    "    results = evaluate_task1b(X_single, df_tied, dataset_names, CLASSIFIERS, scale_features=False, desc=\"\")\n",
    "    \n",
    "    for clf_name, res in results.items():\n",
    "        single_metric_task1b.append({\n",
    "            'Metric': metric,\n",
    "            'Classifier': clf_name,\n",
    "            'Accuracy': res['accuracy'],\n",
    "            'Correct': res['correct'],\n",
    "            'Total': res['total']\n",
    "        })\n",
    "\n",
    "df_single_1b = pd.DataFrame(single_metric_task1b)\n",
    "best_single_1b = df_single_1b.loc[df_single_1b['Accuracy'].idxmax()]\n",
    "print(f\"\\nâ˜… Best Single Metric (Task 1-B): {best_single_1b['Metric']} + {best_single_1b['Classifier']} = {best_single_1b['Accuracy']:.4f}\")\n",
    "\n",
    "all_results['single_metric_task1b'] = df_single_1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a0166b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CASE 3: ALL METRICS (24) - TASK 1-A\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All Metrics Task 1-A: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:17<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â˜… Best All Metrics (Task 1-A): SVM-Linear = 0.5714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CASE 3: ALL METRICS (24) - TASK 1-A\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_all_1a = evaluate_task1a(X_all, y, CLASSIFIERS, scale_features=True, desc=\"All Metrics Task 1-A\")\n",
    "\n",
    "all_metrics_task1a = []\n",
    "for clf_name, res in results_all_1a.items():\n",
    "    all_metrics_task1a.append({\n",
    "        'Classifier': clf_name,\n",
    "        'Accuracy': res['accuracy'],\n",
    "        'Correct': res['correct'],\n",
    "        'Total': res['total']\n",
    "    })\n",
    "\n",
    "df_all_1a = pd.DataFrame(all_metrics_task1a).sort_values('Accuracy', ascending=False)\n",
    "best_all_1a = df_all_1a.iloc[0]\n",
    "print(f\"\\nâ˜… Best All Metrics (Task 1-A): {best_all_1a['Classifier']} = {best_all_1a['Accuracy']:.4f}\")\n",
    "\n",
    "all_results['all_metrics_task1a'] = df_all_1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75b7a481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CASE 4: ALL METRICS (24) - TASK 1-B\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All Metrics Task 1-B: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:19<00:00,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â˜… Best All Metrics (Task 1-B): SVM-RBF = 0.9286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CASE 4: ALL METRICS (24) - TASK 1-B\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_all_1b = evaluate_task1b(X_all, df_tied, dataset_names, CLASSIFIERS, scale_features=True, desc=\"All Metrics Task 1-B\")\n",
    "\n",
    "all_metrics_task1b = []\n",
    "for clf_name, res in results_all_1b.items():\n",
    "    all_metrics_task1b.append({\n",
    "        'Classifier': clf_name,\n",
    "        'Accuracy': res['accuracy'],\n",
    "        'Correct': res['correct'],\n",
    "        'Total': res['total']\n",
    "    })\n",
    "\n",
    "df_all_1b = pd.DataFrame(all_metrics_task1b).sort_values('Accuracy', ascending=False)\n",
    "best_all_1b = df_all_1b.iloc[0]\n",
    "print(f\"\\nâ˜… Best All Metrics (Task 1-B): {best_all_1b['Classifier']} = {best_all_1b['Accuracy']:.4f}\")\n",
    "\n",
    "all_results['all_metrics_task1b'] = df_all_1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84f04d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "\n",
      "            Case     Task Best_Config  Accuracy\n",
      "   Single Metric Task 1-A     l2 + RF  0.607143\n",
      "   Single Metric Task 1-B     l3 + DT  0.928571\n",
      "All Metrics (24) Task 1-A  SVM-Linear  0.571429\n",
      "All Metrics (24) Task 1-B     SVM-RBF  0.928571\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "PIVOT TABLE:\n",
      "----------------------------------------------------------------------\n",
      "Task              Task 1-A  Task 1-B\n",
      "Case                                \n",
      "All Metrics (24)  0.571429  0.928571\n",
      "Single Metric     0.607143  0.928571\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary_data = [\n",
    "    {\n",
    "        'Case': 'Single Metric',\n",
    "        'Task': 'Task 1-A',\n",
    "        'Best_Config': f\"{best_single_1a['Metric']} + {best_single_1a['Classifier']}\",\n",
    "        'Accuracy': best_single_1a['Accuracy']\n",
    "    },\n",
    "    {\n",
    "        'Case': 'Single Metric',\n",
    "        'Task': 'Task 1-B',\n",
    "        'Best_Config': f\"{best_single_1b['Metric']} + {best_single_1b['Classifier']}\",\n",
    "        'Accuracy': best_single_1b['Accuracy']\n",
    "    },\n",
    "    {\n",
    "        'Case': 'All Metrics (24)',\n",
    "        'Task': 'Task 1-A',\n",
    "        'Best_Config': best_all_1a['Classifier'],\n",
    "        'Accuracy': best_all_1a['Accuracy']\n",
    "    },\n",
    "    {\n",
    "        'Case': 'All Metrics (24)',\n",
    "        'Task': 'Task 1-B',\n",
    "        'Best_Config': best_all_1b['Classifier'],\n",
    "        'Accuracy': best_all_1b['Accuracy']\n",
    "    },\n",
    "]\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + summary_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"PIVOT TABLE:\")\n",
    "print(\"-\"*70)\n",
    "pivot = summary_df.pivot(index='Case', columns='Task', values='Accuracy')\n",
    "print(pivot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2176aa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAIN TASK 1-B MODELS\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "def train_task1b_models():\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_all)\n",
    "    \n",
    "    X_train_single, X_train_all, y_train_list = [], [], []\n",
    "    \n",
    "    for idx, ds_name in enumerate(dataset_names):\n",
    "        valid_kernels = df_tied.loc[df_tied.index == ds_name, 'Best_Kernel'].tolist()\n",
    "        for kernel in valid_kernels:\n",
    "            X_train_single.append([df.loc[ds_name, 'n4']])\n",
    "            X_train_all.append(X_scaled[idx])\n",
    "            y_train_list.append(kernel)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y_train_list)\n",
    "    \n",
    "    # Model 1: n4 + DT\n",
    "    model_single = DecisionTreeClassifier(random_state=42)\n",
    "    model_single.fit(np.array(X_train_single), y_encoded)\n",
    "    \n",
    "    # Model 2: All + SVM-RBF  \n",
    "    model_all = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, probability=True)\n",
    "    model_all.fit(np.array(X_train_all), y_encoded)\n",
    "    \n",
    "    return {\n",
    "        'single': {'model': model_single, 'feature': 'n4'},\n",
    "        'all': {'model': model_all, 'scaler': scaler},\n",
    "        'encoder': le\n",
    "    }\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAIN TASK 1-B MODELS\")\n",
    "print(\"=\"*70)\n",
    "trained_models = train_task1b_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da51ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "qml_path = (Path.cwd() / \"../../QML\").resolve()\n",
    "sys.path.insert(0, str(qml_path))\n",
    "\n",
    "from Qsun.Qkernels import *\n",
    "from Qsun.Qgates import *\n",
    "from Qsun.Qmeas import *\n",
    "from Qsun.Qcircuit import *\n",
    "from Qsun.Qwave import *\n",
    "from Qsun.Qencodes import *\n",
    "from Qsun.Qdata import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.load_datasets import *\n",
    "from src.kernel_evaluation import *\n",
    "from tqdm import tqdm\n",
    "import problexity as px\n",
    "from sklearn.datasets import load_digits, make_moons, make_circles, make_classification\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b8380f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Digits_0v1: (360, 64) â†’ PCA â†’ (360, 4) (71.6% var)\n",
      "  Moons_n35: (200, 2)\n",
      "  Circles: (200, 2)\n",
      "  Synthetic: (200, 4)\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(X, y, name, max_features=4):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    if X_scaled.shape[1] > max_features:\n",
    "        pca = PCA(n_components=max_features)\n",
    "        X_scaled = pca.fit_transform(X_scaled)\n",
    "        print(f\"  {name}: {X.shape} â†’ PCA â†’ {X_scaled.shape} ({pca.explained_variance_ratio_.sum():.1%} var)\")\n",
    "    else:\n",
    "        print(f\"  {name}: {X_scaled.shape}\")\n",
    "    \n",
    "    return X_scaled, y\n",
    "\n",
    "digits = load_digits()\n",
    "mask = (digits.target == 0) | (digits.target == 1)\n",
    "X_digits, y_digits = prepare_dataset(digits.data[mask], digits.target[mask], \"Digits_0v1\")\n",
    "\n",
    "X_moons, y_moons = make_moons(n_samples=200, noise=0.35, random_state=42)\n",
    "X_moons, y_moons = prepare_dataset(X_moons, y_moons, \"Moons_n35\")\n",
    "\n",
    "X_circles, y_circles = make_circles(n_samples=200, noise=0.1, factor=0.5, random_state=42)\n",
    "X_circles, y_circles = prepare_dataset(X_circles, y_circles, \"Circles\")\n",
    "\n",
    "X_synth, y_synth = make_classification(\n",
    "    n_samples=200, n_features=4, n_informative=3, \n",
    "    n_redundant=1, flip_y=0.1, random_state=42\n",
    ")\n",
    "X_synth, y_synth = prepare_dataset(X_synth, y_synth, \"Synthetic\")\n",
    "\n",
    "test_datasets = {\n",
    "    'Digits_0v1': (X_digits, y_digits),\n",
    "    'Moons_n35': (X_moons, y_moons),\n",
    "    'Circles': (X_circles, y_circles),\n",
    "    'Synthetic': (X_synth, y_synth)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f20698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPUTE COMPLEXITY METRICS FOR TEST DATASETS\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Digits_0v1: shape=(360, 4)\n",
      "   Computed 24 metrics\n",
      "\n",
      "ðŸ“Š Moons_n35: shape=(200, 2)\n",
      "   Computed 24 metrics\n",
      "\n",
      "ðŸ“Š Circles: shape=(200, 2)\n",
      "   Computed 24 metrics\n",
      "\n",
      "ðŸ“Š Synthetic: shape=(200, 4)\n",
      "   Computed 24 metrics\n",
      "\n",
      "âœ“ Test datasets: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPUTE COMPLEXITY METRICS FOR TEST DATASETS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "complexities_test = {}\n",
    "\n",
    "for name, (X, y) in test_datasets.items():\n",
    "    print(f\"\\nðŸ“Š {name}: shape={X.shape}\")\n",
    "    \n",
    "    complexities_runs = []\n",
    "    for i in range(10):\n",
    "        cc = px.ComplexityCalculator()\n",
    "        cc.fit(X, y)\n",
    "        results = list(cc.complexity)\n",
    "        results.append(kolmogorov_complex(X)['best_bytes'])\n",
    "        results.append(intrinsic_dim_from_cov(X))\n",
    "        complexities_runs.append(results)\n",
    "    \n",
    "    complexities_runs = np.array(complexities_runs)\n",
    "    complexities_test[name] = np.mean(complexities_runs, axis=0)\n",
    "    print(f\"   Computed 24 metrics\")\n",
    "\n",
    "df_test = pd.DataFrame(complexities_test, index=metric_columns).T\n",
    "print(f\"\\nâœ“ Test datasets: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24388ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "KERNEL RECOMMENDATIONS\n",
      "======================================================================\n",
      "\n",
      " Digits_0v1:\n",
      "   n4 = 0.0003\n",
      "   Single (n4+DT): HZY_CZ\n",
      "   All (SVM-RBF):  HighDim\n",
      "   Top-3: [(np.str_('SeparableRX'), '0.212'), (np.str_('ZFeatureMap'), '0.210'), (np.str_('HZY_CZ'), '0.206')]\n",
      "\n",
      " Moons_n35:\n",
      "   n4 = 0.1460\n",
      "   Single (n4+DT): HZY_CZ\n",
      "   All (SVM-RBF):  HighDim\n",
      "   Top-3: [(np.str_('SeparableRX'), '0.254'), (np.str_('HZY_CZ'), '0.233'), (np.str_('HighDim'), '0.159')]\n",
      "\n",
      " Circles:\n",
      "   n4 = 0.1835\n",
      "   Single (n4+DT): HardwareEfficientRx\n",
      "   All (SVM-RBF):  HardwareEfficientRx\n",
      "   Top-3: [(np.str_('HighDim'), '0.287'), (np.str_('HZY_CZ'), '0.223'), (np.str_('ZFeatureMap'), '0.151')]\n",
      "\n",
      " Synthetic:\n",
      "   n4 = 0.0840\n",
      "   Single (n4+DT): HighDim\n",
      "   All (SVM-RBF):  HighDim\n",
      "   Top-3: [(np.str_('SeparableRX'), '0.248'), (np.str_('HZY_CZ'), '0.223'), (np.str_('HighDim'), '0.179')]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KERNEL RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "for ds_name in df_test.index:\n",
    "    metrics = df_test.loc[ds_name]\n",
    "    \n",
    "    n4_value = metrics['n4']\n",
    "    X_single = np.array([[n4_value]])\n",
    "    pred_single = trained_models['single']['model'].predict(X_single)\n",
    "    kernel_single = trained_models['encoder'].inverse_transform(pred_single)[0]\n",
    "\n",
    "    X_all_test = metrics[metric_columns].values.reshape(1, -1)\n",
    "    X_all_scaled = trained_models['all']['scaler'].transform(X_all_test)\n",
    "    pred_all = trained_models['all']['model'].predict(X_all_scaled)\n",
    "    kernel_all = trained_models['encoder'].inverse_transform(pred_all)[0]\n",
    "\n",
    "    proba = trained_models['all']['model'].predict_proba(X_all_scaled)[0]\n",
    "    top3 = sorted(zip(trained_models['encoder'].classes_, proba), \n",
    "                  key=lambda x: x[1], reverse=True)[:3]\n",
    "    \n",
    "    recommendations.append({\n",
    "        'Dataset': ds_name,\n",
    "        'n4': n4_value,\n",
    "        'Single(n4+DT)': kernel_single,\n",
    "        'All(SVM-RBF)': kernel_all,\n",
    "        'Top3': top3\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n {ds_name}:\")\n",
    "    print(f\"   n4 = {n4_value:.4f}\")\n",
    "    print(f\"   Single (n4+DT): {kernel_single}\")\n",
    "    print(f\"   All (SVM-RBF):  {kernel_all}\")\n",
    "    print(f\"   Top-3: {[(k, f'{p:.3f}') for k, p in top3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eb7b960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "\n",
      "   Dataset     n4       Single(n4+DT)        All(SVM-RBF) Match\n",
      "Digits_0v1 0.0003              HZY_CZ             HighDim False\n",
      " Moons_n35 0.1460              HZY_CZ             HighDim False\n",
      "   Circles 0.1835 HardwareEfficientRx HardwareEfficientRx  True\n",
      " Synthetic 0.0840             HighDim             HighDim  True\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary_df = pd.DataFrame([{\n",
    "    'Dataset': r['Dataset'],\n",
    "    'n4': f\"{r['n4']:.4f}\",\n",
    "    'Single(n4+DT)': r['Single(n4+DT)'],\n",
    "    'All(SVM-RBF)': r['All(SVM-RBF)'],\n",
    "    'Match': 'True' if r['Single(n4+DT)'] == r['All(SVM-RBF)'] else 'False'\n",
    "} for r in recommendations])\n",
    "\n",
    "print(\"\\n\" + summary_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d0b1131",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING_REGISTER = {\n",
    "    \"YZ_CX\": {\n",
    "        \"fn\": YZ_CX_encode,\n",
    "        \"has_params\": True,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"HighDim\": {\n",
    "        \"fn\": HighDim_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": False,\n",
    "    },\n",
    "    \"HZY_CZ\": {\n",
    "        \"fn\": HZY_CZ_encode,\n",
    "        \"has_params\": True,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"Chebyshev\": {\n",
    "        \"fn\": Chebyshev_encode,\n",
    "        \"has_params\": True,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"ParamZFeatureMap\": {\n",
    "        \"fn\": ParamZFeatureMap_encode,\n",
    "        \"has_params\": True,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"SeparableRX\": {\n",
    "        \"fn\": SeparableRXEncoding_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": False,\n",
    "    },\n",
    "    \"HardwareEfficientRx\": {\n",
    "        \"fn\": HardwareEfficientEmbeddingRx_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"ZFeatureMap\": {\n",
    "        \"fn\": ZFeatureMap_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "    \"ZZFeatureMap\": {\n",
    "        \"fn\": ZZFeatureMap_encode,\n",
    "        \"has_params\": False,\n",
    "        \"has_layers\": True,\n",
    "    },\n",
    "}\n",
    "\n",
    "def encode_sample(sample, encoding_name, n_layers=2, \n",
    "                  params=None):\n",
    "    if encoding_name not in ENCODING_REGISTER:\n",
    "        raise ValueError(f\"Unknown encoding: {encoding_name}\")\n",
    "    config = ENCODING_REGISTER[encoding_name]\n",
    "    fn = config[\"fn\"]\n",
    "    if encoding_name == \"YZ_CX\":\n",
    "        return fn(sample, params=params, n_layers=n_layers)\n",
    "    elif encoding_name == \"HZY_CZ\":\n",
    "        return fn(sample, params=params, n_layers=n_layers)\n",
    "    elif encoding_name == \"Chebyshev\":\n",
    "        return fn(sample, params=params, n_layers=n_layers)\n",
    "    elif encoding_name == \"ParamZFeatureMap\":\n",
    "        return fn(sample, params=params, n_layers=n_layers)\n",
    "    elif encoding_name == \"HardwareEfficientRx\":\n",
    "        return fn(sample, n_layers=n_layers)\n",
    "    elif encoding_name == \"ZFeatureMap\":\n",
    "        return fn(sample, n_layers=n_layers)\n",
    "    elif encoding_name == \"ZZFeatureMap\":\n",
    "        return fn(sample, n_layers=n_layers)\n",
    "    elif encoding_name == \"HighDim\":\n",
    "        return fn(sample)\n",
    "    elif encoding_name == \"SeparableRX\":\n",
    "        return fn(sample)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown encoding: {encoding_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32e777dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_matrix(X_train, X_test,\n",
    "                encoding_name, n_layers=2,\n",
    "                params=None, random_state=42):\n",
    "    n_train = X_train.shape[0]\n",
    "    n_test = X_test.shape[0]\n",
    "    encoded_train = []\n",
    "    for i in range(n_train):\n",
    "        state = encode_sample(X_train[i], encoding_name, n_layers, params)\n",
    "        encoded_train.append(state)\n",
    "    encoded_test = []\n",
    "    for i in range(n_test):\n",
    "        state = encode_sample(X_test[i], encoding_name, n_layers, params)\n",
    "        encoded_test.append(state)\n",
    "    K_train = np.zeros((n_train, n_train))\n",
    "    for i in range(n_train):\n",
    "        for j in range(i, n_train):\n",
    "            k_ij = state_product(encoded_train[i], encoded_train[j])**2\n",
    "            K_train[i, j] = k_ij\n",
    "            K_train[j, i] = k_ij\n",
    "    K_test = np.zeros((n_test, n_train))\n",
    "    for i in range(n_test):\n",
    "        for j in range(n_train):\n",
    "            K_test[i, j] = state_product(encoded_test[i], encoded_train[j])**2\n",
    "    \n",
    "    return K_train, K_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "645c1426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VERIFY: QUANTUM KERNEL ACCURACY\n",
      "======================================================================\n",
      "\n",
      " Digits_0v1: train=288, test=72\n",
      "   Testing HZY_CZ... Train=0.9965, Test=0.9861\n",
      "   Testing HighDim... Train=1.0000, Test=1.0000\n",
      "\n",
      " Moons_n35: train=160, test=40\n",
      "   Testing HZY_CZ... Train=0.8313, Test=0.8500\n",
      "   Testing HighDim... Train=0.8688, Test=0.8750\n",
      "\n",
      " Circles: train=160, test=40\n",
      "   Testing HardwareEfficientRx... Train=0.9812, Test=1.0000\n",
      "\n",
      " Synthetic: train=160, test=40\n",
      "   Testing HighDim... Train=0.9062, Test=0.8500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VERIFY: QUANTUM KERNEL ACCURACY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "verification_results = []\n",
    "\n",
    "for rec in recommendations:\n",
    "    ds_name = rec['Dataset']\n",
    "    X, y = test_datasets[ds_name]\n",
    "    \n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    scaler_pi = MinMaxScaler(feature_range=(0, np.pi))\n",
    "    X_tr_pi = scaler_pi.fit_transform(X_tr)\n",
    "    X_te_pi = scaler_pi.transform(X_te)\n",
    "    \n",
    "    print(f\"\\n {ds_name}: train={len(X_tr)}, test={len(X_te)}\")\n",
    "    \n",
    "    # Láº¥y unique kernels Ä‘Æ°á»£c recommend\n",
    "    kernels_to_test = list(set([rec['Single(n4+DT)'], rec['All(SVM-RBF)']]))\n",
    "    \n",
    "    for kernel_name in kernels_to_test:\n",
    "        print(f\"   Testing {kernel_name}...\", end=\" \")\n",
    "        \n",
    "        try:\n",
    "            K_train, K_test = kernel_matrix(X_tr_pi, X_te_pi, kernel_name, n_layers=2)\n",
    "            \n",
    "            result = evaluate_kernel(K_train, K_test, y_tr, y_te, kernel_name, \"SVM\")\n",
    "            \n",
    "            print(f\"Train={result.train_accuracy:.4f}, Test={result.test_accuracy:.4f}\")\n",
    "            \n",
    "            verification_results.append({\n",
    "                'Dataset': ds_name,\n",
    "                'Kernel': kernel_name,\n",
    "                'Train_Acc': result.train_accuracy,\n",
    "                'Test_Acc': result.test_accuracy,\n",
    "                'Recommended_By': 'Both' if rec['Single(n4+DT)'] == rec['All(SVM-RBF)'] == kernel_name \n",
    "                                  else ('Single metric' if kernel_name == rec['Single(n4+DT)'] else 'All metrics')\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a190d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VERIFICATION RESULTS\n",
      "======================================================================\n",
      "\n",
      "   Dataset              Kernel  Train_Acc  Test_Acc Recommended_By\n",
      "Digits_0v1              HZY_CZ   0.996528  0.986111  Single metric\n",
      "Digits_0v1             HighDim   1.000000  1.000000    All metrics\n",
      " Moons_n35              HZY_CZ   0.831250  0.850000  Single metric\n",
      " Moons_n35             HighDim   0.868750  0.875000    All metrics\n",
      "   Circles HardwareEfficientRx   0.981250  1.000000           Both\n",
      " Synthetic             HighDim   0.906250  0.850000           Both\n",
      "\n",
      "======================================================================\n",
      "TEST ALL KERNELS FOR COMPARISON\n",
      "======================================================================\n",
      "\n",
      " Digits_0v1:\n",
      "   YZ_CX: 0.5417\n",
      "   HighDim: 1.0000\n",
      "   HZY_CZ: 0.9861\n",
      "   Chebyshev: 0.5417\n",
      "   ParamZFeatureMap: 0.7361\n",
      "   SeparableRX: 1.0000\n",
      "   HardwareEfficientRx: 1.0000\n",
      "   ZFeatureMap: 0.9306\n",
      "   ZZFeatureMap: 0.8333\n",
      "\n",
      " Moons_n35:\n",
      "   YZ_CX: 0.5250\n",
      "   HighDim: 0.8750\n",
      "   HZY_CZ: 0.8000\n",
      "   Chebyshev: 0.4500\n",
      "   ParamZFeatureMap: 0.6750\n",
      "   SeparableRX: 0.8000\n",
      "   HardwareEfficientRx: 0.8250\n",
      "   ZFeatureMap: 0.6000\n",
      "   ZZFeatureMap: 0.6250\n",
      "\n",
      " Circles:\n",
      "   YZ_CX: 0.5500\n",
      "   HighDim: 0.9750\n",
      "   HZY_CZ: 0.9750\n",
      "   Chebyshev: 0.4500\n",
      "   ParamZFeatureMap: 0.5000\n",
      "   SeparableRX: 1.0000\n",
      "   HardwareEfficientRx: 1.0000\n",
      "   ZFeatureMap: 1.0000\n",
      "   ZZFeatureMap: 0.8250\n",
      "\n",
      " Synthetic:\n",
      "   YZ_CX: 0.5250\n",
      "   HighDim: 0.8500\n",
      "   HZY_CZ: 0.8500\n",
      "   Chebyshev: 0.4250\n",
      "   ParamZFeatureMap: 0.6500\n",
      "   SeparableRX: 0.8500\n",
      "   HardwareEfficientRx: 0.8500\n",
      "   ZFeatureMap: 0.9250\n",
      "   ZZFeatureMap: 0.8250\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VERIFICATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_verify = pd.DataFrame(verification_results)\n",
    "print(\"\\n\" + df_verify.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST ALL KERNELS FOR COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_kernel_results = []\n",
    "\n",
    "for ds_name in df_test.index:\n",
    "    X, y = test_datasets[ds_name]\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # Scale vá» (0, Ï€) cho quantum kernel\n",
    "    scaler_pi = MinMaxScaler(feature_range=(0, np.pi))\n",
    "    X_tr_pi = scaler_pi.fit_transform(X_tr)\n",
    "    X_te_pi = scaler_pi.transform(X_te)\n",
    "    \n",
    "    print(f\"\\n {ds_name}:\")\n",
    "    \n",
    "    for kernel_name in ENCODING_REGISTER.keys():\n",
    "        try:\n",
    "            K_train, K_test = kernel_matrix(X_tr_pi, X_te_pi, kernel_name, n_layers=2)\n",
    "            result = evaluate_kernel(K_train, K_test, y_tr, y_te, kernel_name, \"SVM\")\n",
    "            \n",
    "            all_kernel_results.append({\n",
    "                'Dataset': ds_name,\n",
    "                'Kernel': kernel_name,\n",
    "                'Test_Acc': result.test_accuracy\n",
    "            })\n",
    "            print(f\"   {kernel_name}: {result.test_accuracy:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   {kernel_name}: Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15710501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RECOMMENDATION ACCURACY\n",
      "======================================================================\n",
      "\n",
      "   Dataset Actual_Best Best_Acc          Rec_Single Single_Acc             Rec_All All_Acc\n",
      "Digits_0v1     HighDim   1.0000              HZY_CZ     0.9861             HighDim  1.0000\n",
      " Moons_n35     HighDim   0.8750              HZY_CZ     0.8000             HighDim  0.8750\n",
      "   Circles SeparableRX   1.0000 HardwareEfficientRx     1.0000 HardwareEfficientRx  1.0000\n",
      " Synthetic ZFeatureMap   0.9250             HighDim     0.8500             HighDim  0.8500\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDATION ACCURACY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_all_kernels = pd.DataFrame(all_kernel_results)\n",
    "\n",
    "comparison_table = []\n",
    "for ds_name in df_test.index:\n",
    "    rec = next(r for r in recommendations if r['Dataset'] == ds_name)\n",
    "    ds_results = df_all_kernels[df_all_kernels['Dataset'] == ds_name]\n",
    "    \n",
    "    if len(ds_results) > 0:\n",
    "        actual_best = ds_results.loc[ds_results['Test_Acc'].idxmax()]\n",
    "        \n",
    "        rec_single = ds_results[ds_results['Kernel'] == rec['Single(n4+DT)']]\n",
    "        rec_all = ds_results[ds_results['Kernel'] == rec['All(SVM-RBF)']]\n",
    "        \n",
    "        single_acc = rec_single['Test_Acc'].values[0] if len(rec_single) > 0 else None\n",
    "        all_acc = rec_all['Test_Acc'].values[0] if len(rec_all) > 0 else None\n",
    "        \n",
    "        comparison_table.append({\n",
    "            'Dataset': ds_name,\n",
    "            'Actual_Best': actual_best['Kernel'],\n",
    "            'Best_Acc': f\"{actual_best['Test_Acc']:.4f}\",\n",
    "            'Rec_Single': rec['Single(n4+DT)'],\n",
    "            'Single_Acc': f\"{single_acc:.4f}\" if single_acc else \"N/A\",\n",
    "            'Rec_All': rec['All(SVM-RBF)'],\n",
    "            'All_Acc': f\"{all_acc:.4f}\" if all_acc else \"N/A\",\n",
    "        })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_table)\n",
    "print(\"\\n\" + df_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "124dcd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VERIFY WITH MULTIPLE RUNS (n_runs=10)\n",
      "======================================================================\n",
      "\n",
      " Digits_0v1:\n",
      "   YZ_CX: 0.4889 Â± 0.0447\n",
      "   HighDim: 1.0000 Â± 0.0000\n",
      "   HZY_CZ: 0.9944 Â± 0.0092\n",
      "   Chebyshev: 0.5500 Â± 0.0616\n",
      "   ParamZFeatureMap: 0.7528 Â± 0.0438\n",
      "   SeparableRX: 0.9986 Â± 0.0042\n",
      "   HardwareEfficientRx: 1.0000 Â± 0.0000\n",
      "   ZFeatureMap: 0.9722 Â± 0.0215\n",
      "   ZZFeatureMap: 0.8972 Â± 0.0418\n",
      "\n",
      " Moons_n35:\n",
      "   YZ_CX: 0.5450 Â± 0.0630\n",
      "   HighDim: 0.8575 Â± 0.0488\n",
      "   HZY_CZ: 0.7975 Â± 0.0530\n",
      "   Chebyshev: 0.5100 Â± 0.0436\n",
      "   ParamZFeatureMap: 0.5650 Â± 0.0339\n",
      "   SeparableRX: 0.7750 Â± 0.0698\n",
      "   HardwareEfficientRx: 0.7875 Â± 0.0700\n",
      "   ZFeatureMap: 0.6600 Â± 0.0572\n",
      "   ZZFeatureMap: 0.6500 Â± 0.0570\n",
      "\n",
      " Circles:\n",
      "   YZ_CX: 0.4900 Â± 0.0604\n",
      "   HighDim: 0.9475 Â± 0.0344\n",
      "   HZY_CZ: 0.9700 Â± 0.0367\n",
      "   Chebyshev: 0.5600 Â± 0.0604\n",
      "   ParamZFeatureMap: 0.5375 Â± 0.0584\n",
      "   SeparableRX: 0.9875 Â± 0.0168\n",
      "   HardwareEfficientRx: 0.9875 Â± 0.0168\n",
      "   ZFeatureMap: 0.9850 Â± 0.0166\n",
      "   ZZFeatureMap: 0.8275 Â± 0.0617\n",
      "\n",
      " Synthetic:\n",
      "   YZ_CX: 0.5100 Â± 0.0421\n",
      "   HighDim: 0.8475 Â± 0.0439\n",
      "   HZY_CZ: 0.8500 Â± 0.0559\n",
      "   Chebyshev: 0.5100 Â± 0.0875\n",
      "   ParamZFeatureMap: 0.6025 Â± 0.0884\n",
      "   SeparableRX: 0.8625 Â± 0.0491\n",
      "   HardwareEfficientRx: 0.8625 Â± 0.0437\n",
      "   ZFeatureMap: 0.8500 Â± 0.0680\n",
      "   ZZFeatureMap: 0.7975 Â± 0.0564\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "n_runs = 10\n",
    "all_run_results = []\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"VERIFY WITH MULTIPLE RUNS (n_runs={n_runs})\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for ds_name in df_test.index:\n",
    "    X, y = test_datasets[ds_name]\n",
    "    print(f\"\\n {ds_name}:\")\n",
    "    \n",
    "    kernel_scores = {k: [] for k in ENCODING_REGISTER.keys()}\n",
    "    \n",
    "    for run in range(n_runs):\n",
    "        seed = 42 + run\n",
    "        \n",
    "        X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "        )\n",
    "        \n",
    "        scaler_pi = MinMaxScaler(feature_range=(0, np.pi))\n",
    "        X_tr_pi = scaler_pi.fit_transform(X_tr)\n",
    "        X_te_pi = scaler_pi.transform(X_te)\n",
    "        \n",
    "        for kernel_name in ENCODING_REGISTER.keys():\n",
    "            try:\n",
    "                K_train, K_test = kernel_matrix(X_tr_pi, X_te_pi, kernel_name, n_layers=2)\n",
    "                result = evaluate_kernel(K_train, K_test, y_tr, y_te, kernel_name, \"SVM\")\n",
    "                kernel_scores[kernel_name].append(result.test_accuracy)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    for kernel_name, scores in kernel_scores.items():\n",
    "        if len(scores) > 0:\n",
    "            mean_acc = np.mean(scores)\n",
    "            std_acc = np.std(scores)\n",
    "            print(f\"   {kernel_name}: {mean_acc:.4f} Â± {std_acc:.4f}\")\n",
    "            \n",
    "            all_run_results.append({\n",
    "                'Dataset': ds_name,\n",
    "                'Kernel': kernel_name,\n",
    "                'Mean_Acc': mean_acc,\n",
    "                'Std_Acc': std_acc,\n",
    "                'n_runs': len(scores)\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db813a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPARISON WITH MULTIPLE RUNS: (n_runs=10)\n",
      "======================================================================\n",
      "\n",
      "Digits_0v1:\n",
      "   Actual Best: HighDim = 1.0000 Â± 0.0000\n",
      "   Rec Single:  HZY_CZ = 0.9944 Â± 0.0092 (gap: 0.0056)\n",
      "   Rec All:     HighDim = 1.0000 Â± 0.0000 (gap: 0.0000)\n",
      "\n",
      "Moons_n35:\n",
      "   Actual Best: HighDim = 0.8575 Â± 0.0488\n",
      "   Rec Single:  HZY_CZ = 0.7975 Â± 0.0530 (gap: 0.0600)\n",
      "   Rec All:     HighDim = 0.8575 Â± 0.0488 (gap: 0.0000)\n",
      "\n",
      "Circles:\n",
      "   Actual Best: SeparableRX = 0.9875 Â± 0.0168\n",
      "   Rec Single:  HardwareEfficientRx = 0.9875 Â± 0.0168 (gap: 0.0000)\n",
      "   Rec All:     HardwareEfficientRx = 0.9875 Â± 0.0168 (gap: 0.0000)\n",
      "\n",
      "Synthetic:\n",
      "   Actual Best: SeparableRX = 0.8625 Â± 0.0491\n",
      "   Rec Single:  HighDim = 0.8475 Â± 0.0439 (gap: 0.0150)\n",
      "   Rec All:     HighDim = 0.8475 Â± 0.0439 (gap: 0.0150)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"COMPARISON WITH MULTIPLE RUNS: (n_runs={n_runs})\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_runs = pd.DataFrame(all_run_results)\n",
    "\n",
    "for ds_name in df_test.index:\n",
    "    rec = next(r for r in recommendations if r['Dataset'] == ds_name)\n",
    "    ds_results = df_runs[df_runs['Dataset'] == ds_name].copy()\n",
    "    \n",
    "    if len(ds_results) > 0:\n",
    "        best_idx = ds_results['Mean_Acc'].idxmax()\n",
    "        actual_best = ds_results.loc[best_idx]\n",
    "        \n",
    "        rec_single_row = ds_results[ds_results['Kernel'] == rec['Single(n4+DT)']]\n",
    "        rec_all_row = ds_results[ds_results['Kernel'] == rec['All(SVM-RBF)']]\n",
    "        \n",
    "        print(f\"\\n{ds_name}:\")\n",
    "        print(f\"   Actual Best: {actual_best['Kernel']} = {actual_best['Mean_Acc']:.4f} Â± {actual_best['Std_Acc']:.4f}\")\n",
    "        \n",
    "        if len(rec_single_row) > 0:\n",
    "            r = rec_single_row.iloc[0]\n",
    "            gap = actual_best['Mean_Acc'] - r['Mean_Acc']\n",
    "            print(f\"   Rec Single:  {rec['Single(n4+DT)']} = {r['Mean_Acc']:.4f} Â± {r['Std_Acc']:.4f} (gap: {gap:.4f})\")\n",
    "        \n",
    "        if len(rec_all_row) > 0:\n",
    "            r = rec_all_row.iloc[0]\n",
    "            gap = actual_best['Mean_Acc'] - r['Mean_Acc']\n",
    "            print(f\"   Rec All:     {rec['All(SVM-RBF)']} = {r['Mean_Acc']:.4f} Â± {r['Std_Acc']:.4f} (gap: {gap:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd058e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FULL RESULTS TABLE (Mean Â± Std over 10 runs)\n",
      "======================================================================\n",
      "\n",
      "Mean Accuracy:\n",
      "Dataset              Circles  Digits_0v1  Moons_n35  Synthetic\n",
      "Kernel                                                        \n",
      "Chebyshev             0.5600      0.5500     0.5100     0.5100\n",
      "HZY_CZ                0.9700      0.9944     0.7975     0.8500\n",
      "HardwareEfficientRx   0.9875      1.0000     0.7875     0.8625\n",
      "HighDim               0.9475      1.0000     0.8575     0.8475\n",
      "ParamZFeatureMap      0.5375      0.7528     0.5650     0.6025\n",
      "SeparableRX           0.9875      0.9986     0.7750     0.8625\n",
      "YZ_CX                 0.4900      0.4889     0.5450     0.5100\n",
      "ZFeatureMap           0.9850      0.9722     0.6600     0.8500\n",
      "ZZFeatureMap          0.8275      0.8972     0.6500     0.7975\n",
      "\n",
      "Std Deviation:\n",
      "Dataset              Circles  Digits_0v1  Moons_n35  Synthetic\n",
      "Kernel                                                        \n",
      "Chebyshev             0.0604      0.0616     0.0436     0.0875\n",
      "HZY_CZ                0.0367      0.0092     0.0530     0.0559\n",
      "HardwareEfficientRx   0.0168      0.0000     0.0700     0.0437\n",
      "HighDim               0.0344      0.0000     0.0488     0.0439\n",
      "ParamZFeatureMap      0.0584      0.0438     0.0339     0.0884\n",
      "SeparableRX           0.0168      0.0042     0.0698     0.0491\n",
      "YZ_CX                 0.0604      0.0447     0.0630     0.0421\n",
      "ZFeatureMap           0.0166      0.0215     0.0572     0.0680\n",
      "ZZFeatureMap          0.0617      0.0418     0.0570     0.0564\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FULL RESULTS TABLE (Mean Â± Std over 10 runs)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "pivot = df_runs.pivot(index='Kernel', columns='Dataset', values='Mean_Acc')\n",
    "pivot_std = df_runs.pivot(index='Kernel', columns='Dataset', values='Std_Acc')\n",
    "\n",
    "print(\"\\nMean Accuracy:\")\n",
    "print(pivot.round(4).to_string())\n",
    "\n",
    "print(\"\\nStd Deviation:\")\n",
    "print(pivot_std.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e3ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tied_candidates(trained_models, metrics, top_k=5):\n",
    "    X_scaled = trained_models['all']['scaler'].transform(metrics.reshape(1, -1))\n",
    "    proba = trained_models['all']['model'].predict_proba(X_scaled)[0]\n",
    "    \n",
    "    kernel_proba = list(zip(trained_models['encoder'].classes_, proba))\n",
    "    kernel_proba.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return kernel_proba[:top_k] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "742371b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Digits_0v1:\n",
      "   SeparableRX: 0.212\n",
      "   ZFeatureMap: 0.210\n",
      "   HZY_CZ: 0.206\n",
      "   HighDim: 0.185\n",
      "   HardwareEfficientRx: 0.133\n",
      "\n",
      "Moons_n35:\n",
      "   SeparableRX: 0.254\n",
      "   HZY_CZ: 0.233\n",
      "   HighDim: 0.159\n",
      "   ZFeatureMap: 0.155\n",
      "   HardwareEfficientRx: 0.150\n",
      "\n",
      "Circles:\n",
      "   HighDim: 0.287\n",
      "   HZY_CZ: 0.223\n",
      "   ZFeatureMap: 0.151\n",
      "   SeparableRX: 0.133\n",
      "   HardwareEfficientRx: 0.133\n",
      "\n",
      "Synthetic:\n",
      "   SeparableRX: 0.248\n",
      "   HZY_CZ: 0.223\n",
      "   HighDim: 0.179\n",
      "   ZFeatureMap: 0.154\n",
      "   HardwareEfficientRx: 0.149\n"
     ]
    }
   ],
   "source": [
    "for ds_name in df_test.index:\n",
    "    metrics = df_test.loc[ds_name, metric_columns].values\n",
    "    tied = get_tied_candidates(trained_models, metrics, top_k=5)\n",
    "    \n",
    "    print(f\"\\n{ds_name}:\")\n",
    "    for kernel, prob in tied:\n",
    "        print(f\"   {kernel}: {prob:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
